{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Purpose of script:**\n",
    "\n",
    "Creating new features \n",
    "\n",
    "- In: dataframe_plain\n",
    "- Out: dataframe_extended (with additional feature columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray\n",
    "import rasterio\n",
    "import gemgis as gg\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from astral.sun import sun\n",
    "from astral import LocationInfo\n",
    "import pyproj\n",
    "from math import asin, cos, atan, tan, pi, acos, sin \n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Relevant paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataframe_plain = r\"../Data/combined/dataframe_plain/\"\n",
    "mw_path = r\"../Data/microwave-rs/mw_interpolated/\"\n",
    "path_elevation =  r\"../Data/elevation_data/gimpdem_1km_compressed.tif\"\n",
    "out_path = r\"../Data/combined/dataframe_extended/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Row and column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_row_and_col(df):\n",
    "        # add row and column features:\n",
    "        df['col'] = df.groupby(\"x\").ngroup() # xshape 2663 \n",
    "        df['row'] = df.groupby(\"y\").ngroup(ascending=False) # yshape 1462\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_date_year(df, melt_date):\n",
    "    date = pd.to_datetime(melt_date).date()\n",
    "    df['date'] = date\n",
    "    df['year'] = date.year\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Aggregated/pooled values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "from typing import Tuple\n",
    "from scipy.stats import mode\n",
    "from scipy.signal import convolve2d\n",
    "\n",
    "def get_window(image: np.ndarray, window_size: int, center: Tuple[int, int]) -> np.ndarray:\n",
    "    top = max(center[0] - window_size // 2, 0)\n",
    "    bottom = min(center[0] + window_size // 2 + 1, image.shape[0])\n",
    "    left = max(center[1] - window_size // 2, 0)\n",
    "    right = min(center[1] + window_size // 2 + 1, image.shape[1])\n",
    "    window = image[top:bottom, left:right]\n",
    "    return window\n",
    "\n",
    "\n",
    "# need to fix? : only calculate if the middle value is not nan - else all nan columns around 1 and 0 are going to have a value.\n",
    "\n",
    "def convolve(image, window_size, convolution_fn: Union['mean', 'min', 'max', 'sum']):\n",
    "    image = image[0].values\n",
    "    image[image == -1] = np.nan\n",
    "    \n",
    "    if convolution_fn == 'mean':\n",
    "        kernel = np.ones((window_size, window_size))  # kernel for mean convolution\n",
    "        result = np.zeros_like(image, dtype=np.float64)\n",
    "        # Compute the sum and count of non-NaN values in the kernel window\n",
    "        counts = convolve2d(~np.isnan(image), kernel, mode='same', boundary='fill', fillvalue=0)\n",
    "        sums = convolve2d(np.nan_to_num(image), kernel, mode='same', boundary='fill', fillvalue=0)\n",
    "        # Calculate the mean, ignoring NaN values\n",
    "        result[counts > 0] = sums[counts > 0] / counts[counts > 0]\n",
    "        # Set the output to NaN where all values in the kernel window are NaN\n",
    "        result[counts == 0] = np.nan\n",
    "        return result\n",
    "        \n",
    "    elif convolution_fn == 'max':\n",
    "        result = np.zeros_like(image, dtype=np.float64)\n",
    "        for i in range(image.shape[0]):\n",
    "            for j in range(image.shape[1]):\n",
    "                window = get_window(image, window_size, (i, j))\n",
    "                non_nan_values = window[~np.isnan(window)]\n",
    "                if len(non_nan_values) == 0:\n",
    "                    result[i, j] = np.nan\n",
    "                else:\n",
    "                    result[i, j] = np.nanmax(non_nan_values)\n",
    "\n",
    "    elif convolution_fn == 'min':\n",
    "        result = np.zeros_like(image, dtype=np.float64)\n",
    "        for i in range(image.shape[0]):\n",
    "            for j in range(image.shape[1]):\n",
    "                window = get_window(image, window_size, (i, j))\n",
    "                non_nan_values = window[~np.isnan(window)]\n",
    "                if len(non_nan_values) == 0:\n",
    "                    result[i, j] = np.nan\n",
    "                else:\n",
    "                    result[i, j] = np.nanmin(non_nan_values)\n",
    "        return result\n",
    "\n",
    "    elif convolution_fn == 'sum':\n",
    "        result = np.zeros_like(image, dtype=np.float64)\n",
    "        for i in range(image.shape[0]):\n",
    "            for j in range(image.shape[1]):\n",
    "                window = get_window(image, window_size, (i, j))\n",
    "                non_nan_values = window[~np.isnan(window)]\n",
    "                if len(non_nan_values) == 0:\n",
    "                    result[i, j] = np.nan\n",
    "                else:\n",
    "                    result[i, j] = np.nansum(non_nan_values)\n",
    "        return result\n",
    "        \n",
    "    else: \n",
    "        print('not available function')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution_to_df(convolution_raster, column_name):\n",
    "    nrows, ncols = convolution_raster.shape\n",
    "    # create an array of x and y positions\n",
    "    x = np.tile(np.arange(ncols), nrows)\n",
    "    y = np.repeat(np.arange(nrows), ncols)\n",
    "    # create a DataFrame with x, y, and pixel values as columns\n",
    "    df = pd.DataFrame({'col': x, 'row': y, column_name: convolution_raster.flatten()})\n",
    "    return df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Elevation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_elevation(data):\n",
    "    df = data.to_dataframe()\n",
    "    df = df.reset_index()\n",
    "    df = df[['x', 'y', 'band_data']]\n",
    "    df.rename({'band_data': 'elevation_data'}, axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Slope"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slope is given as degree of incline angle: 0 means flat (no slope == horizontal), 90 means (most possible slope == vertical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_slope(data):\n",
    "    slope = gg.raster.calculate_slope(data)\n",
    "    nrows, ncols = slope.shape\n",
    "    # create an array of x and y positions\n",
    "    x = np.tile(np.arange(ncols), nrows)\n",
    "    y = np.repeat(np.arange(nrows), ncols)\n",
    "    # create a DataFrame with x, y, and pixel values as columns\n",
    "    df_slope = pd.DataFrame({'col': x, 'row': y, 'slope_data': slope.flatten()})\n",
    "    return df_slope"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Aspect"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aspect is given as cosine radian: 0 and 360 degree = 1, 180 degree = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aspect(data):\n",
    "    aspect = gg.raster.calculate_aspect(data)\n",
    "    nrows, ncols = aspect.shape\n",
    "    # create an array of x and y positions\n",
    "    x = np.tile(np.arange(ncols), nrows)\n",
    "    y = np.repeat(np.arange(nrows), ncols)\n",
    "    # create a DataFrame with x, y, and pixel values as columns\n",
    "    df_aspect = pd.DataFrame({'col': x, 'row': y, 'aspect_data': aspect.flatten()})\n",
    "    df_aspect[\"aspect_data\"] = np.cos(df_aspect[\"aspect_data\"] * np.pi / 180.)\n",
    "    return df_aspect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Distance from margin/shore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_to_margin():\n",
    "    data_microwave = xarray.open_dataarray(mw_path + '2019-06-08_mw.tif') # any microwave file\n",
    "    mw_val_masked = data_microwave[0].values\n",
    "    mw_val_masked = np.copy(mw_val_masked)\n",
    "    mw_val_masked[mw_val_masked==1]=0\n",
    "    dist_in_pixels = scipy.ndimage.morphology.distance_transform_edt(mw_val_masked==0, return_distances= True)\n",
    "    return dist_in_pixels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Array to DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_to_df(convolution_raster, column_name):\n",
    "    nrows, ncols = convolution_raster.shape\n",
    "    # create an array of x and y positions\n",
    "    x = np.tile(np.arange(ncols), nrows)\n",
    "    y = np.repeat(np.arange(nrows), ncols)\n",
    "    # create a DataFrame with x, y, and pixel values as columns\n",
    "    df = pd.DataFrame({'col': x, 'row': y, column_name: convolution_raster.flatten()})\n",
    "    return df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(mw_path, path_dataframe_plain):\n",
    "    # get plain files:\n",
    "    df_plain_files = [f for f in listdir(path_dataframe_plain) if isfile(join(path_dataframe_plain, f))]\n",
    "    # microwave files:\n",
    "    mw_files = [f for f in listdir(mw_path) if isfile(join(mw_path, f))]\n",
    "    return  mw_files, df_plain_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(mw_files_list, df_plain_files_list, path_elevation, out_path, write = False):\n",
    "    # get plain files:\n",
    "    df_plain_files = df_plain_files_list\n",
    "    # microwave files:\n",
    "    mw_files = mw_files_list\n",
    "    # load elevation data:\n",
    "    data_elevation_xarray = xarray.open_dataarray(path_elevation)\n",
    "    data_elevation_rasterio = rasterio.open(path_elevation)\n",
    "    # calculate distance to margin:\n",
    "    distance_margin = distance_to_margin()\n",
    "\n",
    "    for df_file in df_plain_files:\n",
    "        melt_date =  df_file[5:15]\n",
    "        print(melt_date)\n",
    "        for mw_file in mw_files:\n",
    "            if mw_file.startswith(melt_date):\n",
    "                data_mw = xarray.open_dataarray(mw_path + mw_file)\n",
    "                df = pd.read_parquet(path_dataframe_plain + df_file)\n",
    "                # add row and column features:\n",
    "                df = add_row_and_col(df)\n",
    "                # get convolutions:\n",
    "                df_conv_mean_3 = array_to_df(convolve(data_mw, 3, 'mean'), 'mean_3')\n",
    "                df_conv_mean_9 = array_to_df(convolve(data_mw, 9, 'mean'), 'mean_9')\n",
    "                df_conv_sum_5 = array_to_df(convolve(data_mw, 5, 'sum'), 'sum_5')\n",
    "                # merge convolution:\n",
    "                df_combined = pd.merge(df, df_conv_mean_3, how = 'left', on = ['row', 'col'])\n",
    "                df_combined = pd.merge(df_combined, df_conv_mean_9, how = 'left', on = ['row', 'col'])\n",
    "                df_combined = pd.merge(df_combined, df_conv_sum_5, how = 'left', on = ['row', 'col'])\n",
    "                # remove water in mw:\n",
    "                df_combined = df_combined.loc[df_combined['mw_value'] != -1]\n",
    "                # add date:\n",
    "                df = add_date_year(df_combined, melt_date)\n",
    "                # add and merge elevation data:\n",
    "                df_elevation = add_elevation(data_elevation_xarray)\n",
    "                df = pd.merge(df, df_elevation, how = 'left', on = ['y', 'x'])\n",
    "                # get and merge slope data:\n",
    "                df_slope = get_slope(data_elevation_rasterio)\n",
    "                df = pd.merge(df, df_slope[[\"slope_data\"]], how=\"left\", right_index=True, left_index=True)\n",
    "                # get and merge aspect data:\n",
    "                df_aspect = get_aspect(data_elevation_rasterio)\n",
    "                df = pd.merge(df, df_aspect[[\"aspect_data\"]], how=\"left\", right_index=True, left_index=True) \n",
    "                # add and merge distance to margin data:\n",
    "                df_distance = array_to_df(distance_margin, 'distance_to_margin')\n",
    "                df = pd.merge(df, df_distance, how = 'left', on = ['row', 'col'])\n",
    "                \n",
    "                # write to parquet:\n",
    "                if write == True:\n",
    "                    df.to_parquet(out_path + 'melt_'+ melt_date + '_extended.parquet.gzip', index= False)                    \n",
    "    return df\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main(mw_path, path_dataframe_plain, path_elevation, out_path)\n",
    "main(*get_files(mw_path, path_dataframe_plain), path_elevation, out_path)# , write = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Lina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-08\n"
     ]
    }
   ],
   "source": [
    "df = main(['2019-06-08_mw.tif'], ['melt_2019-06-08.parquet.gzip'], path_elevation, out_path, write= True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>mw_value</th>\n",
       "      <th>opt_value</th>\n",
       "      <th>col</th>\n",
       "      <th>row</th>\n",
       "      <th>mean_3</th>\n",
       "      <th>mean_9</th>\n",
       "      <th>sum_5</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>elevation_data</th>\n",
       "      <th>slope_data</th>\n",
       "      <th>aspect_data</th>\n",
       "      <th>distance_to_margin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-636500.00</td>\n",
       "      <td>-662500.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2019-06-08</td>\n",
       "      <td>2019</td>\n",
       "      <td>14.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>150.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-635500.00</td>\n",
       "      <td>-662500.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2019-06-08</td>\n",
       "      <td>2019</td>\n",
       "      <td>14.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>150.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-634500.00</td>\n",
       "      <td>-662500.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2019-06-08</td>\n",
       "      <td>2019</td>\n",
       "      <td>14.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>150.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-633500.00</td>\n",
       "      <td>-662500.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2019-06-08</td>\n",
       "      <td>2019</td>\n",
       "      <td>14.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>150.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-632500.00</td>\n",
       "      <td>-662500.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2019-06-08</td>\n",
       "      <td>2019</td>\n",
       "      <td>14.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>150.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2278720</th>\n",
       "      <td>58500.00</td>\n",
       "      <td>-3324500.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>695</td>\n",
       "      <td>2662</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2019-06-08</td>\n",
       "      <td>2019</td>\n",
       "      <td>44.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.93</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2278721</th>\n",
       "      <td>59500.00</td>\n",
       "      <td>-3324500.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>696</td>\n",
       "      <td>2662</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2019-06-08</td>\n",
       "      <td>2019</td>\n",
       "      <td>44.00</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.89</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2278722</th>\n",
       "      <td>60500.00</td>\n",
       "      <td>-3324500.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>697</td>\n",
       "      <td>2662</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2019-06-08</td>\n",
       "      <td>2019</td>\n",
       "      <td>44.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.89</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2278723</th>\n",
       "      <td>61500.00</td>\n",
       "      <td>-3324500.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>698</td>\n",
       "      <td>2662</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2019-06-08</td>\n",
       "      <td>2019</td>\n",
       "      <td>45.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2278724</th>\n",
       "      <td>62500.00</td>\n",
       "      <td>-3324500.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>699</td>\n",
       "      <td>2662</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2019-06-08</td>\n",
       "      <td>2019</td>\n",
       "      <td>45.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2278725 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 x           y  mw_value  opt_value  col   row  mean_3  \\\n",
       "0       -636500.00  -662500.00      0.00      -1.00    0     0    0.00   \n",
       "1       -635500.00  -662500.00      0.00      -1.00    1     0    0.00   \n",
       "2       -634500.00  -662500.00      0.00      -1.00    2     0    0.00   \n",
       "3       -633500.00  -662500.00      0.00      -1.00    3     0    0.00   \n",
       "4       -632500.00  -662500.00      0.00      -1.00    4     0    0.00   \n",
       "...            ...         ...       ...        ...  ...   ...     ...   \n",
       "2278720   58500.00 -3324500.00      0.00      -1.00  695  2662    0.00   \n",
       "2278721   59500.00 -3324500.00      0.00      -1.00  696  2662    0.00   \n",
       "2278722   60500.00 -3324500.00      0.00      -1.00  697  2662    0.00   \n",
       "2278723   61500.00 -3324500.00      0.00      -1.00  698  2662    0.00   \n",
       "2278724   62500.00 -3324500.00      0.00      -1.00  699  2662    0.00   \n",
       "\n",
       "         mean_9  sum_5        date  year  elevation_data  slope_data  \\\n",
       "0          0.00   0.00  2019-06-08  2019           14.00        0.00   \n",
       "1          0.00   0.00  2019-06-08  2019           14.00        0.00   \n",
       "2          0.00   0.00  2019-06-08  2019           14.00        0.00   \n",
       "3          0.00   0.00  2019-06-08  2019           14.00        0.00   \n",
       "4          0.00   0.00  2019-06-08  2019           14.00        0.00   \n",
       "...         ...    ...         ...   ...             ...         ...   \n",
       "2278720    0.00   0.00  2019-06-08  2019           44.00        0.15   \n",
       "2278721    0.00   0.00  2019-06-08  2019           44.00        0.13   \n",
       "2278722    0.00   0.00  2019-06-08  2019           44.00        0.06   \n",
       "2278723    0.00   0.00  2019-06-08  2019           45.00        0.06   \n",
       "2278724    0.00   0.00  2019-06-08  2019           45.00        0.19   \n",
       "\n",
       "         aspect_data  distance_to_margin  \n",
       "0               1.00              150.00  \n",
       "1               1.00              150.00  \n",
       "2               1.00              150.00  \n",
       "3               1.00              150.00  \n",
       "4               1.00              150.00  \n",
       "...              ...                 ...  \n",
       "2278720         0.93                5.00  \n",
       "2278721         0.89                4.00  \n",
       "2278722         0.89                3.00  \n",
       "2278723        -0.45                2.00  \n",
       "2278724        -0.45                1.00  \n",
       "\n",
       "[2278725 rows x 15 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for testing values around the 0-1 change in the data:\n",
    "\n",
    "# tt = data_mw.values\n",
    "# # indices = np.where(tt == 1)\n",
    "# tt[0][74:80, 622:628]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([81.53389148, 81.54025102, 81.54660541, ..., 59.98367852,\n",
       "       59.98352011, 59.98335911])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the source and destination coordinate reference systems\n",
    "src_crs = pyproj.CRS.from_epsg(3413)  # WGS84 (longitude, latitude)\n",
    "dst_crs = pyproj.CRS.from_epsg(4326)  # Web Mercator (used by most online maps)\n",
    "\n",
    "# Define the transformer object\n",
    "transformer = pyproj.Transformer.from_crs(src_crs, dst_crs)\n",
    "# Convert all coordinates at once\n",
    "lats, longs = transformer.transform(df[\"x\"], df[\"y\"])\n",
    "\n",
    "lats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>mw_value</th>\n",
       "      <th>opt_value</th>\n",
       "      <th>col</th>\n",
       "      <th>row</th>\n",
       "      <th>mean_3</th>\n",
       "      <th>mean_9</th>\n",
       "      <th>sum_5</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>elevation_data</th>\n",
       "      <th>slope_data</th>\n",
       "      <th>aspect_data</th>\n",
       "      <th>distance_to_margin</th>\n",
       "      <th>lats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-636500.00</td>\n",
       "      <td>-662500.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2019-06-08</td>\n",
       "      <td>2019</td>\n",
       "      <td>14.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>150.00</td>\n",
       "      <td>81.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-635500.00</td>\n",
       "      <td>-662500.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2019-06-08</td>\n",
       "      <td>2019</td>\n",
       "      <td>14.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>150.00</td>\n",
       "      <td>81.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-634500.00</td>\n",
       "      <td>-662500.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2019-06-08</td>\n",
       "      <td>2019</td>\n",
       "      <td>14.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>150.00</td>\n",
       "      <td>81.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-633500.00</td>\n",
       "      <td>-662500.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2019-06-08</td>\n",
       "      <td>2019</td>\n",
       "      <td>14.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>150.00</td>\n",
       "      <td>81.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-632500.00</td>\n",
       "      <td>-662500.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2019-06-08</td>\n",
       "      <td>2019</td>\n",
       "      <td>14.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>150.00</td>\n",
       "      <td>81.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2278720</th>\n",
       "      <td>58500.00</td>\n",
       "      <td>-3324500.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>695</td>\n",
       "      <td>2662</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2019-06-08</td>\n",
       "      <td>2019</td>\n",
       "      <td>44.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.93</td>\n",
       "      <td>5.00</td>\n",
       "      <td>59.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2278721</th>\n",
       "      <td>59500.00</td>\n",
       "      <td>-3324500.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>696</td>\n",
       "      <td>2662</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2019-06-08</td>\n",
       "      <td>2019</td>\n",
       "      <td>44.00</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.89</td>\n",
       "      <td>4.00</td>\n",
       "      <td>59.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2278722</th>\n",
       "      <td>60500.00</td>\n",
       "      <td>-3324500.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>697</td>\n",
       "      <td>2662</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2019-06-08</td>\n",
       "      <td>2019</td>\n",
       "      <td>44.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.89</td>\n",
       "      <td>3.00</td>\n",
       "      <td>59.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2278723</th>\n",
       "      <td>61500.00</td>\n",
       "      <td>-3324500.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>698</td>\n",
       "      <td>2662</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2019-06-08</td>\n",
       "      <td>2019</td>\n",
       "      <td>45.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>2.00</td>\n",
       "      <td>59.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2278724</th>\n",
       "      <td>62500.00</td>\n",
       "      <td>-3324500.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>699</td>\n",
       "      <td>2662</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2019-06-08</td>\n",
       "      <td>2019</td>\n",
       "      <td>45.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>1.00</td>\n",
       "      <td>59.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2278725 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 x           y  mw_value  opt_value  col   row  mean_3  \\\n",
       "0       -636500.00  -662500.00      0.00      -1.00    0     0    0.00   \n",
       "1       -635500.00  -662500.00      0.00      -1.00    1     0    0.00   \n",
       "2       -634500.00  -662500.00      0.00      -1.00    2     0    0.00   \n",
       "3       -633500.00  -662500.00      0.00      -1.00    3     0    0.00   \n",
       "4       -632500.00  -662500.00      0.00      -1.00    4     0    0.00   \n",
       "...            ...         ...       ...        ...  ...   ...     ...   \n",
       "2278720   58500.00 -3324500.00      0.00      -1.00  695  2662    0.00   \n",
       "2278721   59500.00 -3324500.00      0.00      -1.00  696  2662    0.00   \n",
       "2278722   60500.00 -3324500.00      0.00      -1.00  697  2662    0.00   \n",
       "2278723   61500.00 -3324500.00      0.00      -1.00  698  2662    0.00   \n",
       "2278724   62500.00 -3324500.00      0.00      -1.00  699  2662    0.00   \n",
       "\n",
       "         mean_9  sum_5        date  year  elevation_data  slope_data  \\\n",
       "0          0.00   0.00  2019-06-08  2019           14.00        0.00   \n",
       "1          0.00   0.00  2019-06-08  2019           14.00        0.00   \n",
       "2          0.00   0.00  2019-06-08  2019           14.00        0.00   \n",
       "3          0.00   0.00  2019-06-08  2019           14.00        0.00   \n",
       "4          0.00   0.00  2019-06-08  2019           14.00        0.00   \n",
       "...         ...    ...         ...   ...             ...         ...   \n",
       "2278720    0.00   0.00  2019-06-08  2019           44.00        0.15   \n",
       "2278721    0.00   0.00  2019-06-08  2019           44.00        0.13   \n",
       "2278722    0.00   0.00  2019-06-08  2019           44.00        0.06   \n",
       "2278723    0.00   0.00  2019-06-08  2019           45.00        0.06   \n",
       "2278724    0.00   0.00  2019-06-08  2019           45.00        0.19   \n",
       "\n",
       "         aspect_data  distance_to_margin  lats  \n",
       "0               1.00              150.00 81.53  \n",
       "1               1.00              150.00 81.54  \n",
       "2               1.00              150.00 81.55  \n",
       "3               1.00              150.00 81.55  \n",
       "4               1.00              150.00 81.56  \n",
       "...              ...                 ...   ...  \n",
       "2278720         0.93                5.00 59.98  \n",
       "2278721         0.89                4.00 59.98  \n",
       "2278722         0.89                3.00 59.98  \n",
       "2278723        -0.45                2.00 59.98  \n",
       "2278724        -0.45                1.00 59.98  \n",
       "\n",
       "[2278725 rows x 16 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"lats\"] = lats\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fe81b6f13d6b0ad05b54a8d717c7eaa3743b1b1bf0e5cb2d6ec80103feaa1c84"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
