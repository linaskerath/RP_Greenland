{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Purpose of script:**\n",
    "\n",
    "Creating new features \n",
    "\n",
    "- In: dataframe_plain\n",
    "- Out: dataframe_extended (with additional feature columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Relevant paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataframe_plain = r\"../Data/combined/dataframe_plain/\"\n",
    "mw_path = r\"../Data/microwave-rs/mw_interpolated/\"\n",
    "path_elevation =  r\"../Data/elevation_data/gimpdem_1km_compressed.tif\"\n",
    "out_path = r\"../Data/combined/dataframe_extended/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Row and column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_row_and_col(df):\n",
    "        # add row and column features:\n",
    "        df['col'] = df.groupby(\"x\").ngroup() # xshape 2663 \n",
    "        df['row'] = df.groupby(\"y\").ngroup(ascending=False) # yshape 1462\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_date(df):\n",
    "    df['date'] = '2019-07-01'\n",
    "    df[\"date\"]= pd.to_datetime(df[\"date\"])\n",
    "    # df['month'] = df[\"date\"].dt.month\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Aggregated/pooled values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_neighbors(matrix, a, b):\n",
    "#     neighbors = [matrix[i][j] if (i > -1 and j > -1 and j < len(matrix[0]) and i < len(matrix)) else np.nan for i in range(a-1, a+2) for j in range(b-1, b+2) ]\n",
    "#     return neighbors\n",
    "\n",
    "# def get_neighbours_df(data):\n",
    "#     index_list = [(i,j) for i in range(data.shape[1]) for j in range(data.shape[2])]\n",
    "#     value_list = []\n",
    "#     values = data.values[0]\n",
    "\n",
    "#     for i in tqdm(index_list):\n",
    "#         neighbor = get_neighbors(values, *i)\n",
    "#         neighbor += [i[0], i[1]]\n",
    "#         value_list.append(neighbor)\n",
    "\n",
    "#     df_neighbors = pd.DataFrame(value_list, columns = ['v1', 'v2', 'v3','v4', 'v5', 'v6','v7', 'v8', 'v9', 'row', 'col'])   \n",
    "#     return df_neighbors\n",
    "\n",
    "# def add_aggregated(df):\n",
    "#     cols = ['v1', 'v2', 'v3', 'v4', 'v5', 'v6', 'v7', 'v8', 'v9'] # delet v5? same as mw value\n",
    "#     df[cols] = df[cols].replace(-1, np.NaN) # to skip -1 when calculating mean\n",
    "#     df['mean'] = df[cols].mean(axis = 1) # mean value of 9 pixels around\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "from typing import Tuple\n",
    "from scipy.stats import mode\n",
    "from scipy.signal import convolve2d\n",
    "\n",
    "def get_window(image: np.ndarray, window_size: int, center: Tuple[int, int]) -> np.ndarray:\n",
    "    top = max(center[0] - window_size // 2, 0)\n",
    "    bottom = min(center[0] + window_size // 2 + 1, image.shape[0])\n",
    "    left = max(center[1] - window_size // 2, 0)\n",
    "    right = min(center[1] + window_size // 2 + 1, image.shape[1])\n",
    "    window = image[top:bottom, left:right]\n",
    "    return window\n",
    "\n",
    "\n",
    "# need to fix? : only calculate if the middle value is not nan - else all nan columns around 1 and 0 are going to have a value.\n",
    "# -1 to nan\n",
    "\n",
    "def convolve(image, window_size, convolution_fn: Union['mean', 'min', 'max', 'sum', 'median', 'mode']):\n",
    "    image = image[0].values\n",
    "    image[image == -1] = np.nan\n",
    "    \n",
    "    if convolution_fn == 'mean':\n",
    "        kernel = np.ones((window_size, window_size))  # kernel for mean convolution\n",
    "        result = np.zeros_like(image, dtype=np.float64)\n",
    "        # Compute the sum and count of non-NaN values in the kernel window\n",
    "        counts = convolve2d(~np.isnan(image), kernel, mode='same', boundary='fill', fillvalue=0)\n",
    "        sums = convolve2d(np.nan_to_num(image), kernel, mode='same', boundary='fill', fillvalue=0)\n",
    "        # Calculate the mean, ignoring NaN values\n",
    "        result[counts > 0] = sums[counts > 0] / counts[counts > 0]\n",
    "        # Set the output to NaN where all values in the kernel window are NaN\n",
    "        result[counts == 0] = np.nan\n",
    "        return result\n",
    "    elif convolution_fn == 'max':\n",
    "        result = np.zeros_like(image, dtype=np.float64)\n",
    "        for i in range(image.shape[0]):\n",
    "            for j in range(image.shape[1]):\n",
    "                window = get_window(image, window_size, (i, j))\n",
    "                non_nan_values = window[~np.isnan(window)]\n",
    "                if len(non_nan_values) == 0:\n",
    "                    result[i, j] = np.nan\n",
    "                else:\n",
    "                    result[i, j] = np.nanmax(non_nan_values)\n",
    "        return result\n",
    "\n",
    "    elif convolution_fn == 'min':\n",
    "        result = np.zeros_like(image, dtype=np.float64)\n",
    "        for i in range(image.shape[0]):\n",
    "            for j in range(image.shape[1]):\n",
    "                window = get_window(image, window_size, (i, j))\n",
    "                non_nan_values = window[~np.isnan(window)]\n",
    "                if len(non_nan_values) == 0:\n",
    "                    result[i, j] = np.nan\n",
    "                else:\n",
    "                    result[i, j] = np.nanmin(non_nan_values)\n",
    "        return result\n",
    "\n",
    "    elif convolution_fn == 'sum':\n",
    "        result = np.zeros_like(image, dtype=np.float64)\n",
    "        for i in range(image.shape[0]):\n",
    "            for j in range(image.shape[1]):\n",
    "                window = get_window(image, window_size, (i, j))\n",
    "                non_nan_values = window[~np.isnan(window)]\n",
    "                if len(non_nan_values) == 0:\n",
    "                    result[i, j] = np.nan\n",
    "                else:\n",
    "                    result[i, j] = np.nansum(non_nan_values)\n",
    "        return result\n",
    "        \n",
    "    elif convolution_fn == 'median':\n",
    "        result = np.zeros_like(image, dtype=np.float64)\n",
    "        for i in range(image.shape[0]):\n",
    "            for j in range(image.shape[1]):\n",
    "                window = get_window(image, window_size, (i, j))\n",
    "                non_nan_values = window[~np.isnan(window)]\n",
    "                if len(non_nan_values) == 0:\n",
    "                    result[i, j] = np.nan\n",
    "                else:\n",
    "                    result[i, j] = np.nanmedian(non_nan_values)\n",
    "        return result\n",
    "    elif convolution_fn == 'mode':\n",
    "        result = np.zeros_like(image, dtype=np.float64)\n",
    "        for i in range(image.shape[0]):\n",
    "            for j in range(image.shape[1]):\n",
    "                window = get_window(image, window_size, (i, j))\n",
    "                non_nan_values = window[~np.isnan(window)]\n",
    "                if len(non_nan_values) == 0:\n",
    "                    result[i, j] = np.nan\n",
    "                else:\n",
    "                    result[i, j] = mode(non_nan_values)[0]\n",
    "        return result\n",
    "    else: \n",
    "        print('not available function')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution_to_df(convolution_raster):\n",
    "    nrows, ncols = convolution_raster.shape\n",
    "    # create an array of x and y positions\n",
    "    x = np.tile(np.arange(ncols), nrows)\n",
    "    y = np.repeat(np.arange(nrows), ncols)\n",
    "    # create a DataFrame with x, y, and pixel values as columns\n",
    "    df = pd.DataFrame({'col': x, 'row': y, 'mean': convolution_raster.flatten()})\n",
    "    return df \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Elevation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_elevation(data):\n",
    "    df = data.to_dataframe()\n",
    "    df = df.reset_index()\n",
    "    df = df[['x', 'y', 'band_data']]\n",
    "    df.rename({'band_data': 'elevation_data'}, axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Distance from margin/shore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tbd\n",
    "# add if coast column - if at least one na but not all "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(mw_path, path_dataframe_plain, path_elevation, out_path):\n",
    "    # get plain files:\n",
    "    df_plain_files = [f for f in listdir(path_dataframe_plain) if isfile(join(path_dataframe_plain, f))]\n",
    "    # microwave files:\n",
    "    mw_files = [f for f in listdir(mw_path) if isfile(join(mw_path, f))]\n",
    "    # elevation file:\n",
    "    data_elevation = xarray.open_dataarray(path_elevation)\n",
    "\n",
    "    for df_file in df_plain_files:\n",
    "        melt_date =  df_file[5:15]\n",
    "        print(melt_date)\n",
    "        for mw_file in mw_files:\n",
    "            if mw_file.startswith(melt_date):\n",
    "                data_mw = xarray.open_dataarray(mw_path + mw_file)\n",
    "                df = pd.read_parquet(path_dataframe_plain + df_file)\n",
    "                # add row and column features:\n",
    "                df = add_row_and_col(df)\n",
    "                # get neighbours:\n",
    "                # df_neighbors = get_neighbours_df(data_mw)\n",
    "                # merge neighbours:\n",
    "                # df_combined = pd.merge(df, df_neighbors, how = 'left', on = ['row', 'col'])\n",
    "                # get convolution:\n",
    "                convolution = convolve(data_mw, 3, 'mean')\n",
    "                # convolution to df:\n",
    "                df_conv = convolution_to_df(convolution)\n",
    "                # merge convolution:\n",
    "                df_combined = pd.merge(df, df_conv, how = 'left', on = ['row', 'col'])\n",
    "                # remove water in mw:\n",
    "                df_combined = df_combined.loc[df_combined['mw_value'] != -1] # suppress warning?\n",
    "                # add date:\n",
    "                df = add_date(df_combined)\n",
    "                # add aggregations:\n",
    "                # df = add_aggregated(df)\n",
    "                # add elevation data:\n",
    "                df_elevation = add_elevation(data_elevation)\n",
    "                # merge elevation data:\n",
    "                df_with_elevation = pd.merge(df, df_elevation, how = 'left', on = ['y', 'x']) # left smaller mw, right - opt               \n",
    "                # write to parquet:\n",
    "                df_with_elevation.to_parquet(out_path + 'melt_'+ melt_date + '_extended.parquet.gzip', index= False)                    \n",
    "    return\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3893306/3893306 [00:33<00:00, 117824.02it/s]\n"
     ]
    }
   ],
   "source": [
    "main(mw_path, path_dataframe_plain, path_elevation, out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "melt_date =  '2019-06-08'\n",
    "#data_elevation = xarray.open_dataarray(path_elevation)\n",
    "data_mw = xarray.open_dataarray(mw_path + '2019-06-08_mw.tif')\n",
    "df = pd.read_parquet(path_dataframe_plain + 'melt_2019-06-08.parquet.gzip')\n",
    "\n",
    "# add row and column features:\n",
    "df = add_row_and_col(df)\n",
    "# # get neighbours:\n",
    "# df_neighbors = get_neighbours_df(data_mw)\n",
    "# print(data_mw)\n",
    "# print(df_neighbors)\n",
    "\n",
    "test1 = convolve(data_mw, 3, 'mean')\n",
    "df_conv = convolution_to_df(test1)\n",
    "df_combined = pd.merge(df, df_conv, how = 'left', on = ['row', 'col'])\n",
    "# # merge neighbours:\n",
    "# df_combined = pd.merge(df, df_neighbors, how = 'left', on = ['row', 'col'])\n",
    "# # remove water in mw:\n",
    "# df_combined = df_combined.loc[df_combined['mw_value'] != -1] # suppress warning?\n",
    "# # add date:\n",
    "# df = add_date(df_combined)\n",
    "# # add aggregations:\n",
    "# df = add_aggregated(df)\n",
    "\n",
    "\n",
    "# # add elevation data:\n",
    "# df_elevation = add_elevation(data_elevation)\n",
    "# # merge elevation data:\n",
    "# df_with_elevation = pd.merge(df, df_elevation, how = 'left', on = ['y', 'x']) # left smaller mw, right - opt\n",
    "                \n",
    "# # write to parquet:\n",
    "# df_with_elevation.to_parquet(out_path + 'melt_'+ melt_date + '_extended.parquet.gzip', index= False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for testing purposes:\n",
    "\n",
    "tt = data_mw.values\n",
    "# indices = np.where(tt == 1)\n",
    "tt[0][74:80, 622:628]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix1 = np.array([\n",
    "#     [1, 2,      np.nan,   4, 5],\n",
    "#     [6, np.nan,  8,       9, 10],\n",
    "#     [11,        12, 13,  14, 15],\n",
    "#     [16, np.nan, 18,    19, 20],\n",
    "#     [21,  22,    23, np.nan, 25]\n",
    "# ])\n",
    "\n",
    "# import numpy as np\n",
    "# from typing import Tuple\n",
    "# from scipy.signal import convolve2d\n",
    "\n",
    "# def convolve_by_mean(image, window_size):\n",
    "#     kernel = np.ones((window_size, window_size))  # kernel for mean convolution\n",
    "#     result = np.zeros_like(image, dtype=np.float64)\n",
    "#     # Compute the sum and count of non-NaN values in the kernel window\n",
    "#     counts = convolve2d(~np.isnan(image), kernel, mode='same', boundary='fill', fillvalue=0)\n",
    "#     sums = convolve2d(np.nan_to_num(image), kernel, mode='same', boundary='fill', fillvalue=0)\n",
    "#     # Calculate the mean, ignoring NaN values\n",
    "#     result[counts > 0] = sums[counts > 0] / counts[counts > 0]\n",
    "#     # Set the output to NaN where all values in the kernel window are NaN\n",
    "#     result[counts == 0] = np.nan\n",
    "#     return result\n",
    "\n",
    "# def convolve_by_min(image: np.ndarray, window_size: int) -> np.ndarray:\n",
    "#     result = np.zeros_like(image, dtype=np.float64)\n",
    "#     for i in range(image.shape[0]):\n",
    "#         for j in range(image.shape[1]):\n",
    "#             window = get_window(image, window_size, (i, j))\n",
    "#             non_nan_values = window[~np.isnan(window)]\n",
    "#             if len(non_nan_values) == 0:\n",
    "#                 result[i, j] = np.nan\n",
    "#             else:\n",
    "#                 result[i, j] = np.nanmin(non_nan_values)\n",
    "#     return result\n",
    "\n",
    "# def convolve_by_max(image: np.ndarray, window_size: int) -> np.ndarray:\n",
    "#     result = np.zeros_like(image, dtype=np.float64)\n",
    "#     for i in range(image.shape[0]):\n",
    "#         for j in range(image.shape[1]):\n",
    "#             window = get_window(image, window_size, (i, j))\n",
    "#             non_nan_values = window[~np.isnan(window)]\n",
    "#             if len(non_nan_values) == 0:\n",
    "#                 result[i, j] = np.nan\n",
    "#             else:\n",
    "#                 result[i, j] = np.nanmax(non_nan_values)\n",
    "#     return result\n",
    "\n",
    "# def convolve_by_sum(image: np.ndarray, window_size: int) -> np.ndarray:\n",
    "#     result = np.zeros_like(image, dtype=np.float64)\n",
    "#     for i in range(image.shape[0]):\n",
    "#         for j in range(image.shape[1]):\n",
    "#             window = get_window(image, window_size, (i, j))\n",
    "#             non_nan_values = window[~np.isnan(window)]\n",
    "#             if len(non_nan_values) == 0:\n",
    "#                 result[i, j] = np.nan\n",
    "#             else:\n",
    "#                 result[i, j] = np.nansum(non_nan_values)\n",
    "#     return result\n",
    "\n",
    "# def convolve_by_median(image: np.ndarray, window_size: int) -> np.ndarray:\n",
    "#     result = np.zeros_like(image, dtype=np.float64)\n",
    "#     for i in range(image.shape[0]):\n",
    "#         for j in range(image.shape[1]):\n",
    "#             window = get_window(image, window_size, (i, j))\n",
    "#             non_nan_values = window[~np.isnan(window)]\n",
    "#             if len(non_nan_values) == 0:\n",
    "#                 result[i, j] = np.nan\n",
    "#             else:\n",
    "#                 result[i, j] = np.nanmedian(non_nan_values)\n",
    "#     return result\n",
    "\n",
    "# def convolve_by_mode(image: np.ndarray, window_size: int) -> np.ndarray:\n",
    "#     result = np.zeros_like(image, dtype=np.float64)\n",
    "#     for i in range(image.shape[0]):\n",
    "#         for j in range(image.shape[1]):\n",
    "#             window = get_window(image, window_size, (i, j))\n",
    "#             non_nan_values = window[~np.isnan(window)]\n",
    "#             if len(non_nan_values) == 0:\n",
    "#                 result[i, j] = np.nan\n",
    "#             else:\n",
    "#                 result[i, j] = mode(non_nan_values)[0]\n",
    "#     return result\n",
    "\n",
    "# def get_window(image: np.ndarray, window_size: int, center: Tuple[int, int]) -> np.ndarray:\n",
    "#     top = max(center[0] - window_size // 2, 0)\n",
    "#     bottom = min(center[0] + window_size // 2 + 1, image.shape[0])\n",
    "#     left = max(center[1] - window_size // 2, 0)\n",
    "#     right = min(center[1] + window_size // 2 + 1, image.shape[1])\n",
    "#     window = image[top:bottom, left:right]\n",
    "#     return window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.14 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c1c6eaedbd5b3fcd114378d998a879d4f50715202363f6507059361ed549ecef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
