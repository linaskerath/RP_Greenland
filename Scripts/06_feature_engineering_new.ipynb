{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Purpose of script:**\n",
    "\n",
    "Creating new features \n",
    "\n",
    "- In: dataframe_plain\n",
    "- Out: dataframe_extended (with additional feature columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Relevant paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataframe_plain = r\"../Data/combined/dataframe_plain/\"\n",
    "mw_path = r\"../Data/microwave-rs/mw_interpolated/\"\n",
    "path_elevation =  r\"../Data/elevation_data/gimpdem_1km_compressed.tif\"\n",
    "out_path = r\"../Data/combined/dataframe_extended/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Row and column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_row_and_col(df):\n",
    "        # add row and column features:\n",
    "        df['col'] = df.groupby(\"x\").ngroup() # xshape 2663 \n",
    "        df['row'] = df.groupby(\"y\").ngroup(ascending=False) # yshape 1462\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_date(df):\n",
    "    df['date'] = '2019-07-01'\n",
    "    df[\"date\"]= pd.to_datetime(df[\"date\"])\n",
    "    # df['month'] = df[\"date\"].dt.month\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Aggregated/pooled values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "from typing import Tuple\n",
    "from scipy.stats import mode\n",
    "from scipy.signal import convolve2d\n",
    "\n",
    "def get_window(image: np.ndarray, window_size: int, center: Tuple[int, int]) -> np.ndarray:\n",
    "    top = max(center[0] - window_size // 2, 0)\n",
    "    bottom = min(center[0] + window_size // 2 + 1, image.shape[0])\n",
    "    left = max(center[1] - window_size // 2, 0)\n",
    "    right = min(center[1] + window_size // 2 + 1, image.shape[1])\n",
    "    window = image[top:bottom, left:right]\n",
    "    return window\n",
    "\n",
    "\n",
    "# need to fix? : only calculate if the middle value is not nan - else all nan columns around 1 and 0 are going to have a value.\n",
    "\n",
    "def convolve(image, window_size, convolution_fn: Union['mean', 'min', 'max', 'sum', 'median', 'mode']):\n",
    "    image = image[0].values\n",
    "    image[image == -1] = np.nan\n",
    "    \n",
    "    if convolution_fn == 'mean':\n",
    "        kernel = np.ones((window_size, window_size))  # kernel for mean convolution\n",
    "        result = np.zeros_like(image, dtype=np.float64)\n",
    "        # Compute the sum and count of non-NaN values in the kernel window\n",
    "        counts = convolve2d(~np.isnan(image), kernel, mode='same', boundary='fill', fillvalue=0)\n",
    "        sums = convolve2d(np.nan_to_num(image), kernel, mode='same', boundary='fill', fillvalue=0)\n",
    "        # Calculate the mean, ignoring NaN values\n",
    "        result[counts > 0] = sums[counts > 0] / counts[counts > 0]\n",
    "        # Set the output to NaN where all values in the kernel window are NaN\n",
    "        result[counts == 0] = np.nan\n",
    "        return result\n",
    "    elif convolution_fn == 'max':\n",
    "        result = np.zeros_like(image, dtype=np.float64)\n",
    "        for i in range(image.shape[0]):\n",
    "            for j in range(image.shape[1]):\n",
    "                window = get_window(image, window_size, (i, j))\n",
    "                non_nan_values = window[~np.isnan(window)]\n",
    "                if len(non_nan_values) == 0:\n",
    "                    result[i, j] = np.nan\n",
    "                else:\n",
    "                    result[i, j] = np.nanmax(non_nan_values)\n",
    "        return result\n",
    "\n",
    "    elif convolution_fn == 'min':\n",
    "        result = np.zeros_like(image, dtype=np.float64)\n",
    "        for i in range(image.shape[0]):\n",
    "            for j in range(image.shape[1]):\n",
    "                window = get_window(image, window_size, (i, j))\n",
    "                non_nan_values = window[~np.isnan(window)]\n",
    "                if len(non_nan_values) == 0:\n",
    "                    result[i, j] = np.nan\n",
    "                else:\n",
    "                    result[i, j] = np.nanmin(non_nan_values)\n",
    "        return result\n",
    "\n",
    "    elif convolution_fn == 'sum':\n",
    "        result = np.zeros_like(image, dtype=np.float64)\n",
    "        for i in range(image.shape[0]):\n",
    "            for j in range(image.shape[1]):\n",
    "                window = get_window(image, window_size, (i, j))\n",
    "                non_nan_values = window[~np.isnan(window)]\n",
    "                if len(non_nan_values) == 0:\n",
    "                    result[i, j] = np.nan\n",
    "                else:\n",
    "                    result[i, j] = np.nansum(non_nan_values)\n",
    "        return result\n",
    "        \n",
    "    elif convolution_fn == 'median':\n",
    "        result = np.zeros_like(image, dtype=np.float64)\n",
    "        for i in range(image.shape[0]):\n",
    "            for j in range(image.shape[1]):\n",
    "                window = get_window(image, window_size, (i, j))\n",
    "                non_nan_values = window[~np.isnan(window)]\n",
    "                if len(non_nan_values) == 0:\n",
    "                    result[i, j] = np.nan\n",
    "                else:\n",
    "                    result[i, j] = np.nanmedian(non_nan_values)\n",
    "        return result\n",
    "    elif convolution_fn == 'mode':\n",
    "        result = np.zeros_like(image, dtype=np.float64)\n",
    "        for i in range(image.shape[0]):\n",
    "            for j in range(image.shape[1]):\n",
    "                window = get_window(image, window_size, (i, j))\n",
    "                non_nan_values = window[~np.isnan(window)]\n",
    "                if len(non_nan_values) == 0:\n",
    "                    result[i, j] = np.nan\n",
    "                else:\n",
    "                    result[i, j] = mode(non_nan_values)[0]\n",
    "        return result\n",
    "    else: \n",
    "        print('not available function')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution_to_df(convolution_raster, column = Union['mean', 'min', 'max', 'sum', 'median', 'mode']):\n",
    "    nrows, ncols = convolution_raster.shape\n",
    "    # create an array of x and y positions\n",
    "    x = np.tile(np.arange(ncols), nrows)\n",
    "    y = np.repeat(np.arange(nrows), ncols)\n",
    "    # create a DataFrame with x, y, and pixel values as columns\n",
    "    df = pd.DataFrame({'col': x, 'row': y, column: convolution_raster.flatten()})\n",
    "    return df \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Elevation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_elevation(data):\n",
    "    df = data.to_dataframe()\n",
    "    df = df.reset_index()\n",
    "    df = df[['x', 'y', 'band_data']]\n",
    "    df.rename({'band_data': 'elevation_data'}, axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Distance from margin/shore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tbd\n",
    "# add if coast column - if at least one na but not all "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(mw_path, path_dataframe_plain):\n",
    "    # get plain files:\n",
    "    df_plain_files = [f for f in listdir(path_dataframe_plain) if isfile(join(path_dataframe_plain, f))]\n",
    "    # microwave files:\n",
    "    mw_files = [f for f in listdir(mw_path) if isfile(join(mw_path, f))]\n",
    "    return  mw_files, df_plain_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(mw_files_list, df_plain_files_list, path_elevation, out_path, write = False):\n",
    "    # get plain files:\n",
    "    df_plain_files = df_plain_files_list\n",
    "    # microwave files:\n",
    "    mw_files = mw_files_list\n",
    "    # load elevation data:\n",
    "    data_elevation = xarray.open_dataarray(path_elevation)   \n",
    "\n",
    "    for df_file in df_plain_files:\n",
    "        melt_date =  df_file[5:15]\n",
    "        print(melt_date)\n",
    "        for mw_file in mw_files:\n",
    "            if mw_file.startswith(melt_date):\n",
    "                data_mw = xarray.open_dataarray(mw_path + mw_file)\n",
    "                df = pd.read_parquet(path_dataframe_plain + df_file)\n",
    "                # add row and column features:\n",
    "                df = add_row_and_col(df)\n",
    "                # get convolution:\n",
    "                convolution_function = 'mean'\n",
    "                convolution = convolve(data_mw, 3, convolution_function)\n",
    "                # convolution to df:\n",
    "                df_conv = convolution_to_df(convolution, convolution_function)\n",
    "                # merge convolution:\n",
    "                df_combined = pd.merge(df, df_conv, how = 'left', on = ['row', 'col'])\n",
    "                # remove water in mw:\n",
    "                df_combined = df_combined.loc[df_combined['mw_value'] != -1] # suppress warning?\n",
    "                # add date:\n",
    "                df = add_date(df_combined)\n",
    "                # add elevation data:\n",
    "                df_elevation = add_elevation(data_elevation)\n",
    "                # merge elevation data:\n",
    "                df_with_elevation = pd.merge(df, df_elevation, how = 'left', on = ['y', 'x']) # left smaller mw, right - opt               \n",
    "                \n",
    "                # write to parquet:\n",
    "                if write == True:\n",
    "                    df_with_elevation.to_parquet(out_path + 'melt_'+ melt_date + '_extended.parquet.gzip', index= False)                    \n",
    "    return df_with_elevation\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main(mw_path, path_dataframe_plain, path_elevation, out_path)\n",
    "main(*get_files(mw_path, path_dataframe_plain), path_elevation, out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Lina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-08\n"
     ]
    }
   ],
   "source": [
    "df = main(['2019-06-08_mw.tif'], ['melt_2019-06-08.parquet.gzip'], path_elevation, out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>mw_value</th>\n",
       "      <th>opt_value</th>\n",
       "      <th>col</th>\n",
       "      <th>row</th>\n",
       "      <th>mean</th>\n",
       "      <th>date</th>\n",
       "      <th>elevation_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-636500.0</td>\n",
       "      <td>-662500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-635500.0</td>\n",
       "      <td>-662500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-634500.0</td>\n",
       "      <td>-662500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-633500.0</td>\n",
       "      <td>-662500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-632500.0</td>\n",
       "      <td>-662500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2278720</th>\n",
       "      <td>58500.0</td>\n",
       "      <td>-3324500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>695</td>\n",
       "      <td>2662</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2278721</th>\n",
       "      <td>59500.0</td>\n",
       "      <td>-3324500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>696</td>\n",
       "      <td>2662</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2278722</th>\n",
       "      <td>60500.0</td>\n",
       "      <td>-3324500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>697</td>\n",
       "      <td>2662</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2278723</th>\n",
       "      <td>61500.0</td>\n",
       "      <td>-3324500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>698</td>\n",
       "      <td>2662</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2278724</th>\n",
       "      <td>62500.0</td>\n",
       "      <td>-3324500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>699</td>\n",
       "      <td>2662</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2278725 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                x          y  mw_value  opt_value  col   row  mean       date  \\\n",
       "0       -636500.0  -662500.0       0.0       -1.0    0     0   0.0 2019-07-01   \n",
       "1       -635500.0  -662500.0       0.0       -1.0    1     0   0.0 2019-07-01   \n",
       "2       -634500.0  -662500.0       0.0       -1.0    2     0   0.0 2019-07-01   \n",
       "3       -633500.0  -662500.0       0.0       -1.0    3     0   0.0 2019-07-01   \n",
       "4       -632500.0  -662500.0       0.0       -1.0    4     0   0.0 2019-07-01   \n",
       "...           ...        ...       ...        ...  ...   ...   ...        ...   \n",
       "2278720   58500.0 -3324500.0       0.0       -1.0  695  2662   0.0 2019-07-01   \n",
       "2278721   59500.0 -3324500.0       0.0       -1.0  696  2662   0.0 2019-07-01   \n",
       "2278722   60500.0 -3324500.0       0.0       -1.0  697  2662   0.0 2019-07-01   \n",
       "2278723   61500.0 -3324500.0       0.0       -1.0  698  2662   0.0 2019-07-01   \n",
       "2278724   62500.0 -3324500.0       0.0       -1.0  699  2662   0.0 2019-07-01   \n",
       "\n",
       "         elevation_data  \n",
       "0                  14.0  \n",
       "1                  14.0  \n",
       "2                  14.0  \n",
       "3                  14.0  \n",
       "4                  14.0  \n",
       "...                 ...  \n",
       "2278720            44.0  \n",
       "2278721            44.0  \n",
       "2278722            44.0  \n",
       "2278723            45.0  \n",
       "2278724            45.0  \n",
       "\n",
       "[2278725 rows x 9 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for testing values around the 0-1 change in the data:\n",
    "\n",
    "# tt = data_mw.values\n",
    "# # indices = np.where(tt == 1)\n",
    "# tt[0][74:80, 622:628]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.14 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c1c6eaedbd5b3fcd114378d998a879d4f50715202363f6507059361ed549ecef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
