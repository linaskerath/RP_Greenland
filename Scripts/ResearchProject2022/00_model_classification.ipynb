{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Purpose of script:**\n",
    "\n",
    "Load the feature engineered data (tif) to investigate the suitability of classification plus testing of different models\n",
    "\n",
    "- In: combined and extended dataframe (tif)\n",
    "- Out: predictions (tif) for 2019-07-15 and 2019-07-31\n",
    "    - decision tree classification with multiclass labels\n",
    "    - decision tree classification with binary labels\n",
    "    - logistic regression with multiclass labels\n",
    "    - logistic regression with binary labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# custom functions:\n",
    "from functions import read_and_prep_parquet, make_binary_labels, make_multiclass_labels, save_prediction_tif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relevant Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = r\"../Data/combined/dataframe_extended/\"\n",
    "out_path =  r\"../Data/results/classification/\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create train set from all of June "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datelist = pd.date_range(start=\"2019-06-01\",end=\"2019-06-30\")\n",
    "train_datelist = [str(day.date()) for day in train_datelist]\n",
    "\n",
    "X_train_df_list = []\n",
    "y_train_df_list = []\n",
    "\n",
    "for day in train_datelist:\n",
    "    try: # becausec some days are missing in the data files (e.g. 2019-06-04)\n",
    "        X_train, y_train = read_and_prep_parquet(df_path + 'melt_' + day + '_extended.parquet.gzip', 'train')\n",
    "        X_train_df_list.append(X_train)\n",
    "        y_train_df_list.append(y_train)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "\n",
    "X_train = pd.concat(X_train_df_list, axis=0)\n",
    "y_train = pd.concat(y_train_df_list, axis=0)\n",
    "\n",
    "del X_train_df_list\n",
    "del y_train_df_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create test set from July 1st to July 14th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datelist = pd.date_range(start=\"2019-07-01\",end=\"2019-07-14\")\n",
    "test_datelist = [str(day.date()) for day in test_datelist]\n",
    "\n",
    "X_test_df_list = []\n",
    "y_test_df_list = []\n",
    "\n",
    "for day in test_datelist:\n",
    "    try: # becausec some days are missing in the data files (e.g. 2019-06-04)\n",
    "        X_test, y_test = read_and_prep_parquet(df_path + 'melt_' + day + '_extended.parquet.gzip', 'test')\n",
    "        X_test_df_list.append(X_test)\n",
    "        y_test_df_list.append(y_test)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "\n",
    "X_test = pd.concat(X_test_df_list, axis=0)\n",
    "y_test = pd.concat(y_test_df_list, axis=0)\n",
    "\n",
    "del X_test_df_list\n",
    "del y_test_df_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train binary classifier on whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;log_loss&#x27;, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;log_loss&#x27;, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(criterion='log_loss', random_state=0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = DecisionTreeClassifier(random_state=0, criterion=\"log_loss\")\n",
    "classifier.fit(X_train, make_binary_labels(y_train))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate accuracy for whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8492624287097301"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted = classifier.predict(X_test)\n",
    "accuracy = accuracy_score(make_binary_labels(y_test), y_predicted)\n",
    "accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict binary labels for 2019-07-15 and 2019-07-31 and calculate accuracy for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-07-15\n",
      "Missing data percentage: 0.6277636538201723\n",
      "Accuracy: 0.8433002352973648\n",
      "Nan percentage: 0.36401715871814283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2278725it [02:01, 18694.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2019-07-31\n",
      "Missing data percentage: 0.7577539499849228\n",
      "Accuracy: 0.644337308007948\n",
      "Nan percentage: 0.5861115316679283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2278725it [02:08, 17667.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for prediction_date in ['2019-07-15', '2019-07-31']: # do one next day (2019-07-15) and one for tha last day of July (2019-07-31)\n",
    "\n",
    "    # get accuracy\n",
    "    X, y = read_and_prep_parquet(df_path + 'melt_' + prediction_date + '_extended.parquet.gzip', 'validate')\n",
    "    y_predicted_binary = classifier.predict(X)\n",
    "    acc = accuracy_score(make_binary_labels(y), y_predicted_binary)\n",
    "    print(prediction_date)\n",
    "    print(f'Missing data percentage: {1-(len(X)/(2663*1462))}')\n",
    "    print(f'Accuracy: {acc}')\n",
    "\n",
    "    # write prediction:\n",
    "    X_predict = read_and_prep_parquet(df_path + 'melt_' + prediction_date + '_extended.parquet.gzip', 'predict') \n",
    "    y_predicted_binary = classifier.predict(X_predict)\n",
    "    path_out = out_path + 'decision_tree_classifier/' + 'dtrc_binary_' + prediction_date + '.tif'\n",
    "    save_prediction_tif(X_predict, y_predicted_binary, path_out)\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiclass (buckets) classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train multiclass classifier on whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;log_loss&#x27;, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;log_loss&#x27;, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(criterion='log_loss', random_state=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = DecisionTreeClassifier(random_state=0, criterion=\"log_loss\")\n",
    "classifier.fit(X_train, make_multiclass_labels(y_train)[\"binned_opt_value_code\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate accuracy for whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5568754092536725"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted = classifier.predict(X_test)\n",
    "accuracy = accuracy_score(make_multiclass_labels(y_test)[\"binned_opt_value_code\"], y_predicted)\n",
    "accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict multiclass labels for 2019-07-15 and 2019-07-31 and calculate accuracy for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-07-15\n",
      "Missing data percentage: 0.6277636538201723\n",
      "Accuracy: 0.4125949642223802\n",
      "Nan percentage: 0.36401715871814283\n",
      "\n",
      "2019-07-31\n",
      "Missing data percentage: 0.7577539499849228\n",
      "Accuracy: 0.303987327411259\n",
      "Nan percentage: 0.5861115316679283\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for prediction_date in ['2019-07-15', '2019-07-31']: # do one next day (2019-07-15) and one for tha last day of July (2019-07-31)\n",
    "\n",
    "    # get accuracy\n",
    "    X, y = read_and_prep_parquet(df_path + 'melt_' + prediction_date + '_extended.parquet.gzip', 'validate')\n",
    "    y_predicted_multiclass = classifier.predict(X)\n",
    "    acc = accuracy_score(make_multiclass_labels(y)[\"binned_opt_value_code\"], y_predicted_multiclass)\n",
    "    print(prediction_date)\n",
    "    print(f'Missing data percentage: {1-(len(X)/(2663*1462))}')\n",
    "    print(f'Accuracy: {acc}')\n",
    "\n",
    "    # write prediction:\n",
    "    X_predict = read_and_prep_parquet(df_path + 'melt_' + prediction_date + '_extended.parquet.gzip', 'predict') \n",
    "    y_predicted_multiclass = classifier.predict(X_predict)\n",
    "    path_out = out_path + 'decision_tree_classifier/' + 'dtrc_multiclass_' + prediction_date + '.tif'\n",
    "    save_prediction_tif(X_predict, y_predicted_multiclass, path_out)\n",
    "\n",
    "    print()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"OLD\" VALUES:\n",
    "\n",
    "Nan percentage: 0.6277636538201723\n",
    "\n",
    "Accuracy: 0.6226444387709336 for 2019-07-15\n",
    "\n",
    "--\n",
    "\n",
    "Nan percentage: 0.7577539499849228\n",
    "\n",
    "Accuracy: 0.2862709380811716 for 2019-07-31\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train binary classifier on whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = LogisticRegression(random_state=0)\n",
    "classifier.fit(X_train, make_binary_labels(y_train))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate accuracy for whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7690444825617601"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted = classifier.predict(X_test)\n",
    "accuracy = accuracy_score(make_binary_labels(y_test), y_predicted)\n",
    "accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict binary labels for 2019-07-15 and 2019-07-31 and calculate accuracy for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-07-15\n",
      "Missing data percentage: 0.6277636538201723\n",
      "Accuracy: 0.7505068208634931\n",
      "Nan percentage: 0.36401715871814283\n",
      "\n",
      "2019-07-31\n",
      "Missing data percentage: 0.7577539499849228\n",
      "Accuracy: 0.3668582964529051\n",
      "Nan percentage: 0.5861115316679283\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for prediction_date in ['2019-07-15', '2019-07-31']: # do one next day (2019-07-15) and one for tha last day of July (2019-07-31)\n",
    "\n",
    "    # get accuracy\n",
    "    X, y = read_and_prep_parquet(df_path + 'melt_' + prediction_date + '_extended.parquet.gzip', 'validate')\n",
    "    y_predicted_binary = classifier.predict(X)\n",
    "    acc = accuracy_score(make_binary_labels(y), y_predicted_binary)\n",
    "    print(prediction_date)\n",
    "    print(f'Missing data percentage: {1-(len(X)/(2663*1462))}')\n",
    "    print(f'Accuracy: {acc}')\n",
    "\n",
    "    # write prediction:\n",
    "    X_predict = read_and_prep_parquet(df_path + 'melt_' + prediction_date + '_extended.parquet.gzip', 'predict') \n",
    "    y_predicted_binary = classifier.predict(X_predict)\n",
    "    path_out = out_path + 'decision_tree_classifier/' + 'dtrc_binary_' + prediction_date + '.tif'\n",
    "    save_prediction_tif(X_predict, y_predicted_binary, path_out)\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiclass (buckets) Classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train multiclass classifier on whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression(random_state=0, solver='liblinear')\n",
    "classifier.fit(X_train, make_multiclass_labels(y_train)[\"binned_opt_value_code\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate accuracy for whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5728542644471752"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted = classifier.predict(X_test)\n",
    "accuracy = accuracy_score(make_multiclass_labels(y_test)[\"binned_opt_value_code\"], y_predicted)\n",
    "accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict multiclass labels for 2019-07-15 and 2019-07-31 and calculate accuracy for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prediction_date in ['2019-07-15', '2019-07-31']: # do one next day (2019-07-15) and one for tha last day of July (2019-07-31)\n",
    "\n",
    "    # get accuracy\n",
    "    X, y = read_and_prep_parquet(df_path + 'melt_' + prediction_date + '_extended.parquet.gzip', 'validate')\n",
    "    y_predicted_multiclass = classifier.predict(X)\n",
    "    acc = accuracy_score(make_multiclass_labels(y)[\"binned_opt_value_code\"], y_predicted_multiclass)\n",
    "    print(prediction_date)\n",
    "    print(f'Missing data percentage: {1-(len(X)/(2663*1462))}')\n",
    "    print(f'Accuracy: {acc}')\n",
    "\n",
    "    # write prediction:\n",
    "    X_predict = read_and_prep_parquet(df_path + 'melt_' + prediction_date + '_extended.parquet.gzip', 'predict') \n",
    "    y_predicted_multiclass = classifier.predict(X_predict)\n",
    "    path_out = out_path + 'decision_tree_classifier/' + 'dtrc_multiclass_' + prediction_date + '.tif'\n",
    "    #save_prediction_tif(X_predict, y_predicted_multiclass, path_out)\n",
    "\n",
    "    print()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"OLD\" VALUES:\n",
    "\n",
    "Nan percentage: 0.6277636538201723\n",
    "\n",
    "Accuracy: 0.5146243177411453 for 2019-07-15\n",
    "\n",
    "--\n",
    "\n",
    "Nan percentage: 0.7577539499849228\n",
    "\n",
    "Accuracy: 0.269387936866079 for 2019-07-31"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('my-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fe81b6f13d6b0ad05b54a8d717c7eaa3743b1b1bf0e5cb2d6ec80103feaa1c84"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
