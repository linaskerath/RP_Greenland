{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions testing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### saving functions, to be updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def save_prediction_tif(X_pred, y_predicted, path_out):\n",
    "#     \"\"\"\n",
    "#     Function to write predictions to .tif.\n",
    "#     Arguments:\n",
    "#         X_pred: data to be predicted on.\n",
    "#         y_predicted: predicted labels in array, or pandas series.\n",
    "#         path_out: path to save .tif file with file name.\n",
    "#     Returns: No return, writes data to path.\n",
    "#     \"\"\"\n",
    "#     # join prediction and coordinates (row, col)\n",
    "#     X_pred[\"prediction\"] = y_predicted\n",
    "\n",
    "#     # original matrix shape:\n",
    "#     nan_matrix = np.full((2663, 1462), np.nan)\n",
    "\n",
    "#     for row in tqdm(X_pred.iterrows()):  # fix progress bar?\n",
    "#         row_index = int(row[1][\"row\"])\n",
    "#         col_index = int(row[1][\"col\"])\n",
    "#         pred_val = row[1][\"prediction\"]\n",
    "#         nan_matrix[row_index][col_index] = pred_val\n",
    "\n",
    "#     # file to take reference metadata from is interpolated transformed file\n",
    "#     path_metadata_reference = r\"../Data/microwave-rs/mw_interpolated/2019-07-01_mw.tif\"\n",
    "\n",
    "#     convert_to_tif(nan_matrix, path_metadata_reference, path_out)\n",
    "\n",
    "#     return\n",
    "\n",
    "\n",
    "# def convert_to_tif(data, path_file_metadata, path_out):\n",
    "#     \"\"\"\n",
    "#     Function to convert data to tif file.\n",
    "#     Arguments:\n",
    "#         data: new file\n",
    "#         path_file_metadata: tif file with metadata matching expected output tif file\n",
    "#         path_out: output tif file destination and name path\n",
    "#     Returns:\n",
    "#         .tif file\n",
    "#     \"\"\"\n",
    "#     with rasterio.open(path_file_metadata) as src:\n",
    "#         kwargs1 = src.meta.copy()\n",
    "\n",
    "#     with rasterio.open(path_out, \"w\", **kwargs1) as dst:\n",
    "#         dst.write_band(1, data)  # numpy array or xarray\n",
    "#     return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thesis 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functions_training_pipeline as f\n",
    "from functions_training_pipeline import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test:**\n",
    "- ~~test~~\n",
    "- different dates\n",
    "- differnt columns\n",
    "- different models\n",
    "- with and wo normalization\n",
    "- test removal for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = r\"../Data/combined/dataframe_extended/\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all columns = 'x', 'y', 'mw_value', 'opt_value', 'date',\n",
    "       'col', 'row', 'mean_3', 'mean_9',\n",
    "       'sum_5', 'mw_value_yesterday', 'mw_value_7_day_average',\n",
    "       'hours_of_daylight', 'elevation_data', 'slope_data', 'aspect_data',\n",
    "       'distance_to_margin'\n",
    "\n",
    "required columns = 'x', 'y', 'mw_value', 'opt_value', 'date'."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### V1 (random forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:04<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not applicable for feature'mw_value'.\n",
      "Not applicable for feature'date'.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "date_from = '2017-08-01'\n",
    "date_to = '2017-08-06'\n",
    "\n",
    "data = f.import_data(date_from, date_to, df_path)\n",
    "data = f.remove_data(data, removeMaskedClouds = True, removeNoMelt = True) \n",
    "data = f.data_normalization(data, data.columns)\n",
    "\n",
    "columns = ['x', 'y', 'mw_value',  'col', 'row'] # 'opt_value', 'date',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = f.Model(model = RandomForestRegressor, name = 'RF_test_2023_04_17')\n",
    "rf.date_tested = '2023-04-17' # optional\n",
    "rf.columns = columns # optional\n",
    "hyperparameters_for_grid = {'n_estimators': [10, 20], 'max_depth':[4, 7]}\n",
    "rf.hyperparameters = rf.create_hyperparameter_grid(hyperparameters_for_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.spatial_cv(data, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.save_object(rf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### V2 (xgboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-09-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:00<00:03,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-09-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:01<00:02,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-09-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:02<00:01,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-09-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:03<00:00,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-09-11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not applicable for feature'mw_value'.\n",
      "Not applicable for feature'date'.\n",
      "Not applicable for feature'mw_value_yesterday'.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "date_from = '2017-09-07'\n",
    "date_to = '2017-09-11'\n",
    "\n",
    "data = f.import_data(date_from, date_to, df_path)\n",
    "data = f.remove_data(data, removeMaskedClouds = True, removeNoMelt = True) \n",
    "data = f.data_normalization(data, data.columns)\n",
    "\n",
    "columns = ['x', 'y', 'mw_value',  'mean_3', 'mean_9'] # 'opt_value', 'date', "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = f.Model(model = GradientBoostingRegressor, name = 'XGB_test_2023_04_17')\n",
    "xgb.date_tested = '2023-04-17' # optional\n",
    "xgb.columns = columns # optional\n",
    "hyperparameters_for_grid = {'min_samples_split':[3,5], 'learning_rate':[0.1, 0.5]}\n",
    "xgb.hyperparameters = xgb.create_hyperparameter_grid(hyperparameters_for_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.spatial_cv(data, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.save_object(xgb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### V3 (linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not applicable for feature'mw_value'.\n",
      "Not applicable for feature'date'.\n",
      "Not applicable for feature'mw_value_yesterday'.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "date_from = '2018-06-13'\n",
    "date_to = '2018-06-14'\n",
    "\n",
    "data = f.import_data(date_from, date_to, df_path)\n",
    "data = f.remove_data(data, removeMaskedClouds = True, removeNoMelt = True) \n",
    "data = f.data_normalization(data, data.columns)\n",
    "\n",
    "columns = ['x', 'y', 'mw_value', 'sum_5', 'mw_value_yesterday'] # 'opt_value', 'date', "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = f.Model(model = LinearRegression, name = 'LR_test_2023_04_17')\n",
    "lr.date_tested = '2023-04-17' # optional\n",
    "lr.columns = columns # optional\n",
    "hyperparameters_for_grid = {'fit_intercept': [True]}\n",
    "lr.hyperparameters = lr.create_hyperparameter_grid(hyperparameters_for_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.spatial_cv(data, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.save_object(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2 = f.Model(model = LinearRegression, name = 'LR_test2_2023_04_21')\n",
    "lr2.date_tested = '2023-04-21' # optional\n",
    "lr2.columns = columns # optional\n",
    "hyperparameters_for_grid = {'fit_intercept': [True, False]}\n",
    "lr2.hyperparameters = lr2.create_hyperparameter_grid(hyperparameters_for_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.spatial_cv(data, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### V4 (ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr = f.Model(model = Ridge, name = 'Ridge_test_2023_04_17')\n",
    "rr.date_tested = '2023-04-17' # optional\n",
    "rr.columns = columns # optional\n",
    "hyperparameters_for_grid = {'alpha': [0.5, 1, 2]}\n",
    "rr.hyperparameters = rr.create_hyperparameter_grid(hyperparameters_for_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.8 s, sys: 38.9 s, total: 1min 6s\n",
      "Wall time: 12.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rr.spatial_cv(data, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.save_object(rr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### V5 (lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### V6 (elasticnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### V7 (decision tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test/compare saved models:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_test = f.load_object()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt2.final_model.predict([[55500,700000,1,0.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get mean and std feature importnace from cv, and plot it? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for model comparison, both plot and table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_predict(model, x_test):\n",
    "    all_predictions = []\n",
    "    for i in range(len(model.trained_model_list)):\n",
    "        pred_one_model = model.trained_model_list[i].predict(x_test)\n",
    "        all_predictions.append(pred_one_model)\n",
    "    mean_prediction = np.mean(all_predictions, axis = 0)\n",
    "    std_prediction = np.std(all_predictions, axis = 0)\n",
    "    return mean_prediction, std_prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions to pandas and then to tif?\n",
    "# also error plot? - from cv or from predictions? \n",
    "# std plot from cv or from predictions?\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot feature importance:\n",
    "# can get std for tree but also from cv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_prediction_tif(X_pred, y_predicted, path_out):\n",
    "    \"\"\"\n",
    "    Function to write predictions to .tif.\n",
    "    Arguments:\n",
    "        X_pred: data to be predicted on.\n",
    "        y_predicted: predicted labels in array, or pandas series.\n",
    "        path_out: path to save .tif file with file name.\n",
    "    Returns: No return, writes data to path.\n",
    "    \"\"\"\n",
    "    # join prediction and coordinates (row, col)\n",
    "    X_pred[\"prediction\"] = y_predicted\n",
    "\n",
    "    # original matrix shape:\n",
    "    nan_matrix = np.full((2663, 1462), np.nan)\n",
    "\n",
    "    for row in tqdm(X_pred.iterrows()):  # fix progress bar?\n",
    "        row_index = int(row[1][\"row\"])\n",
    "        col_index = int(row[1][\"col\"])\n",
    "        pred_val = row[1][\"prediction\"]\n",
    "        nan_matrix[row_index][col_index] = pred_val\n",
    "\n",
    "    # file to take reference metadata from is interpolated transformed file\n",
    "    path_metadata_reference = r\"../Data/microwave-rs/mw_interpolated/2019-07-01_mw.tif\"\n",
    "\n",
    "    convert_to_tif(nan_matrix, path_metadata_reference, path_out)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def convert_to_tif(data, path_file_metadata, path_out):\n",
    "    \"\"\"\n",
    "    Function to convert data to tif file.\n",
    "    Arguments:\n",
    "        data: new file\n",
    "        path_file_metadata: tif file with metadata matching expected output tif file\n",
    "        path_out: output tif file destination and name path\n",
    "    Returns:\n",
    "        .tif file\n",
    "    \"\"\"\n",
    "    with rasterio.open(path_file_metadata) as src:\n",
    "        kwargs1 = src.meta.copy()\n",
    "\n",
    "    with rasterio.open(path_out, \"w\", **kwargs1) as dst:\n",
    "        dst.write_band(1, data)  # numpy array or xarray\n",
    "    return"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.14 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c1c6eaedbd5b3fcd114378d998a879d4f50715202363f6507059361ed549ecef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
