{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions testing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Project 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_tif(data):\n",
    "    \"\"\"\n",
    "    Function to convert data to tif file.\n",
    "    Arguments:\n",
    "        data:\n",
    "    Returns:\n",
    "        tif file\n",
    "    \"\"\"\n",
    "    #if type data\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_prep_parquet(path, purpose):\n",
    "    \"\"\"\n",
    "    Function to read parquet and prepare as train or test data.\n",
    "    Arguments:\n",
    "        path: path to file.\n",
    "        purpose: {'train', 'test', 'validate', 'predict'} purpose of file.\n",
    "    Returns: train/test dataset and label array (specify output datatype!)\n",
    "    \"\"\"\n",
    "    valid = {'train', 'test', 'validate', 'predict'}\n",
    "    if purpose not in valid:\n",
    "        raise ValueError(\"Purpose must be one of %r.\" % valid)\n",
    "\n",
    "    df = pd.read_parquet(path)\n",
    "    if purpose in ['train', 'test', 'validate']:\n",
    "        df = df.loc[df['opt_value'] != -1] # remove mask\n",
    "        df = df.fillna(-1) # fill values to be able to train\n",
    "        X = df[['x', 'y', 'mw_value', 'col', 'row', 'v1', 'v2', 'v3', 'v4', 'v6', 'v7', 'v8', 'v9', 'mean', 'elevation_data']] # v5 is duplicated\n",
    "        y = df[['opt_value']]\n",
    "        return X, y\n",
    "    else:\n",
    "        df = df.fillna(-1) # fill values to be able to train\n",
    "        X = df[['x', 'y', 'mw_value', 'col', 'row', 'v1', 'v2', 'v3', 'v4', 'v6', 'v7', 'v8', 'v9', 'mean', 'elevation_data']] # v5 is duplicated\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rmse(y_real, y_predicted):\n",
    "    return np.sqrt(mean_squared_error(y_real, y_predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray\n",
    "path_elevation =  r\"../Data/elevation_data/gimpdem_1km_compressed.tif\"\n",
    "data_elevation = xarray.open_dataarray(path_elevation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOUNDS:\n",
      "    BoundingBox(left=-637000.0, bottom=-3349000.0, right=850000.0, top=-662000.0)\n",
      "METADATA:\n",
      "    {'driver': 'GTiff', 'dtype': 'int16', 'nodata': None, 'width': 1487, 'height': 2687, 'count': 1, 'crs': CRS.from_epsg(3413), 'transform': Affine(1000.0, 0.0, -637000.0,\n",
      "       0.0, -1000.0, -662000.0)}\n",
      "MORE CRS INFO:\n",
      "    PROJCS[\"WGS 84 / NSIDC Sea Ice Polar Stereographic North\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Polar_Stereographic\"],PARAMETER[\"latitude_of_origin\",70],PARAMETER[\"central_meridian\",-45],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",SOUTH],AXIS[\"Northing\",SOUTH],AUTHORITY[\"EPSG\",\"3413\"]]\n",
      "RESOLUTION:\n",
      "    (1000.0, -1000.0)\n"
     ]
    }
   ],
   "source": [
    "import rasterio\n",
    "\n",
    "def information(path_to_file):\n",
    "    with rasterio.open(path_elevation) as src:\n",
    "        print('BOUNDS:')\n",
    "        print(f'    {src.bounds}')\n",
    "        print('METADATA:')\n",
    "        print(f'    {src.meta}')\n",
    "        #print(src.crs)\n",
    "\n",
    "    data = xarray.open_dataarray(path_elevation)\n",
    "    print('MORE CRS INFO:')\n",
    "    print(f'    {data.spatial_ref.crs_wkt}')\n",
    "    print('RESOLUTION:')\n",
    "    print(f'    {data.rio.resolution()}')\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "# ----band data:----\n",
    "# raster = rasterio.open(optical_path) #,masked=True)\n",
    "#band_arr = raster.read(band_id) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thesis 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "df_path = r\"../Data/combined/dataframe_extended/\"\n",
    "\n",
    "date_from = '2019-07-01'\n",
    "date_to = '2019-07-02'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(date_from:str, date_to:str, df_path:str):\n",
    "    \"\"\"\n",
    "    Imports data and merges into one dataframe.\n",
    "\n",
    "    Args:\n",
    "        date_from (format: 'yyyy-mm-dd'): Period starting date (included).\n",
    "\n",
    "        date_to (format: 'yyyy-mm-dd'): Period end date (included).\n",
    "\n",
    "        df_path: Path to folder with daily data files.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: Dataframe with all merged data.\n",
    "    \"\"\"\n",
    "\n",
    "    date_range = pd.date_range(date_from, date_to) # both ends included\n",
    "    date_range = [str(day.date()) for day in date_range]\n",
    "    df_list = []\n",
    "\n",
    "    for melt_date in tqdm(date_range):\n",
    "        try: # bc some days are empty\n",
    "            file = pd.read_parquet(df_path + 'melt_'+ melt_date + '_extended.parquet.gzip', index= False) \n",
    "            df_list.append(file) # list of df\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "    print(len(df_list))\n",
    "    df = pd.concat(df_list, axis=0) # concat af df to one\n",
    "    del df_list\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_data(df, removeMaskedClouds = True, removeNoMelt = True):\n",
    "    # remove -1 from mw:\n",
    "    df = df[df['mw_value'] != -1]\n",
    "    \n",
    "    if removeMaskedClouds == True:\n",
    "        # remove nan/-1 from opt:\n",
    "        df = df[df['opt_value'] != -1]\n",
    "\n",
    "    if removeNoMelt == True:\n",
    "        # open file\n",
    "        # join with file\n",
    "        melt = pd.read_parquet(r\"../Data/split_indexes/noMelt_indexes.parquet\", index= False)\n",
    "        df = df.merge(melt, how = 'left', on = [\"y\",'x'])\n",
    "        df = df[df['melt'] == 1]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rmse(y_real, y_predicted):\n",
    "    \"\"\"\n",
    "    Calculates RMSE score.\n",
    "\n",
    "    Args:\n",
    "        y_real (): real target values.\n",
    "\n",
    "        y_predicted (): model predicted target values.\n",
    "\n",
    "    Returns:\n",
    "        float: RMSE score.\n",
    "    \"\"\"\n",
    "\n",
    "    return np.sqrt(mean_squared_error(y_real, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old time series cv\n",
    "\n",
    "# def cross_validation(df, columns, train_func, n_splits = 5, hyperparameters = None):\n",
    "#     \"\"\"\n",
    "#     Cross-validation with TimeSeriesSplit.\n",
    "\n",
    "#     Args:\n",
    "#         df (pandas.DataFrame): Full train/ test dataframe.\n",
    "\n",
    "#         columns (list of strings): List of columns to be used in training.\n",
    "\n",
    "#         train_func (function): Custom defined function for training and evaluating model.\n",
    "#                                 E.g.: model_decisionTree()\n",
    "        \n",
    "#         n_splits (int): Number of cv splits.\n",
    "\n",
    "#         hyperparameters (dict, optional): Dictionary with hyperparameters for model.\n",
    "\n",
    "#     Returns:\n",
    "#         list: Two list with <n_splits> RMSE scores for train and test data.\n",
    "#     \"\"\"\n",
    "\n",
    "#     df.sort_values(by=['date'], inplace = True) # sort df by time\n",
    "#     X = df[columns]\n",
    "#     y = df[[\"opt_value\"]]\n",
    "\n",
    "#     rmse_train_list = []\n",
    "#     rmse_test_list = []\n",
    "#     tscv = TimeSeriesSplit(n_splits = n_splits)\n",
    "\n",
    "#     for train_index, test_index in tqdm(tscv.split(X)):\n",
    "#     #for i, (train_index, test_index) in enumerate(tscv.split(X)):\n",
    "#         # print(f\"Fold {i}:\")\n",
    "#         X_train = X.iloc[train_index]\n",
    "#         y_train = y.iloc[train_index]\n",
    "#         X_test  = X.iloc[test_index]\n",
    "#         y_test  = y.iloc[test_index]\n",
    "\n",
    "#         y_predicted_train, y_predicted_test = train_func(X_train, y_train, X_test, y_test, hyperparameters)\n",
    "\n",
    "#         rmse_train = get_rmse(y_train, y_predicted_train)\n",
    "#         rmse_test = get_rmse(y_test, y_predicted_test)\n",
    "\n",
    "#         rmse_train_list.append(rmse_train)\n",
    "#         rmse_test_list.append(rmse_test)\n",
    "\n",
    "#     return rmse_train_list, rmse_test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new spatial cv\n",
    "\n",
    "def spatial_cross_validation(df, columns, train_func, n_splits = 5, hyperparameters = None):\n",
    "    \"\"\"\n",
    "    Cross-validation with TimeSeriesSplit.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): Full train/ test dataframe.\n",
    "\n",
    "        columns (list of strings): List of columns to be used in training.\n",
    "\n",
    "        train_func (function): Custom defined function for training and evaluating model.\n",
    "                                E.g.: model_decisionTree()\n",
    "        \n",
    "        n_splits (int): Number of cv splits.\n",
    "\n",
    "        hyperparameters (dict, optional): Dictionary with hyperparameters for model.\n",
    "\n",
    "    Returns:\n",
    "        list: Two list with <n_splits> RMSE scores for train and test data.\n",
    "    \"\"\"\n",
    "\n",
    "    df.sort_values(by=['date'], inplace = True) # sort df by time\n",
    "    X = df[columns]\n",
    "    y = df[[\"opt_value\"]]\n",
    "\n",
    "    rmse_train_list = []\n",
    "    rmse_test_list = []\n",
    "    tscv = TimeSeriesSplit(n_splits = n_splits)\n",
    "\n",
    "    for train_index, test_index in tqdm(tscv.split(X)):\n",
    "    #for i, (train_index, test_index) in enumerate(tscv.split(X)):\n",
    "        # print(f\"Fold {i}:\")\n",
    "        X_train = X.iloc[train_index]\n",
    "        y_train = y.iloc[train_index]\n",
    "        X_test  = X.iloc[test_index]\n",
    "        y_test  = y.iloc[test_index]\n",
    "\n",
    "        y_predicted_train, y_predicted_test = train_func(X_train, y_train, X_test, y_test, hyperparameters)\n",
    "\n",
    "        rmse_train = get_rmse(y_train, y_predicted_train)\n",
    "        rmse_test = get_rmse(y_test, y_predicted_test)\n",
    "\n",
    "        rmse_train_list.append(rmse_train)\n",
    "        rmse_test_list.append(rmse_test)\n",
    "\n",
    "    return rmse_train_list, rmse_test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_decisionTree(X_train, y_train, X_test, y_test, hyperparameters = None):\n",
    "    \"\"\"\n",
    "    Trains model and predicts target values.\n",
    "\n",
    "    Args:\n",
    "        X_train (pandas.DataFrame): Dataframe with train data.\n",
    "\n",
    "        y_train (pandas.DataFrame): Dataframe with train labels, one column.\n",
    "\n",
    "        X_test (pandas.DataFrame): Dataframe with test data.\n",
    "\n",
    "        y_test (pandas.DataFrame): Dataframe with test labels, one column.\n",
    "\n",
    "        hyperparameters (dict, optional): Dictionary with model parameters.\n",
    "\n",
    "    Returns:\n",
    "        list: Two lists with predicted values for train and test set.\n",
    "    \"\"\"\n",
    "        \n",
    "    if hyperparameters:\n",
    "        regressor = DecisionTreeRegressor(**hyperparameters)\n",
    "    else:\n",
    "        regressor = DecisionTreeRegressor(random_state=0)\n",
    "\n",
    "    regressor.fit(X_train, y_train)\n",
    "    y_predicted_train = regressor.predict(X_train)\n",
    "    y_predicted_test = regressor.predict(X_test)\n",
    "\n",
    "    return y_predicted_train, y_predicted_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_meanBenchmark(y_train, y_test):\n",
    "    \"\"\"\n",
    "    Creates predictions for mean benchmark.\n",
    "\n",
    "    Args:\n",
    "        y_train (pandas.DataFrame): Dataframe with train labels, one column.\n",
    "\n",
    "        y_test (pandas.DataFrame): Dataframe with test labels, one column.\n",
    "\n",
    "    Returns:\n",
    "        list: Lists with predicted values for test set.\n",
    "    \"\"\"\n",
    "\n",
    "    y_predicted = np.full((1, len(y_test)), y_train.mean())[0]\n",
    "\n",
    "    return y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_mwBenchmark(X_test):\n",
    "    \"\"\"\n",
    "    Creates predictions for microwave benchmark by comparing the mw and opt datasets directly.\n",
    "\n",
    "    Args:\n",
    "        X_test (pandas.DataFrame): Dataframe with test data.\n",
    "\n",
    "    Returns:\n",
    "        list: Lists with predicted values for test set.\n",
    "    \"\"\"\n",
    "\n",
    "    y_predicted = X_test['mw_value']\n",
    "\n",
    "    return y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_tune():\n",
    "    # define grid (if grid)\n",
    "    # do cv for each??? - maybe less splits?\n",
    "    # define hyperparameters as a dictionary eg: dt_params = {'max_depth':7, 'criterion': 'squared_error'}\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results():\n",
    "    return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 195.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/Users/linas/OneDrive/Documents/ITU/Semester3/RP_Greenland/RP_Greenland/Scripts/functions_testing.ipynb Cell 23\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/linas/OneDrive/Documents/ITU/Semester3/RP_Greenland/RP_Greenland/Scripts/functions_testing.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m df \u001b[39m=\u001b[39m import_data(date_from, date_to, df_path)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/linas/OneDrive/Documents/ITU/Semester3/RP_Greenland/RP_Greenland/Scripts/functions_testing.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m df\u001b[39m=\u001b[39mdf[[\u001b[39m'\u001b[39m\u001b[39mmw_value\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mopt_value\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m'\u001b[39m]]\n",
      "\u001b[1;32m/mnt/c/Users/linas/OneDrive/Documents/ITU/Semester3/RP_Greenland/RP_Greenland/Scripts/functions_testing.ipynb Cell 23\u001b[0m in \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/linas/OneDrive/Documents/ITU/Semester3/RP_Greenland/RP_Greenland/Scripts/functions_testing.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/linas/OneDrive/Documents/ITU/Semester3/RP_Greenland/RP_Greenland/Scripts/functions_testing.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(df_list))\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/linas/OneDrive/Documents/ITU/Semester3/RP_Greenland/RP_Greenland/Scripts/functions_testing.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mconcat(df_list, axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m) \u001b[39m# concat af df to one\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/linas/OneDrive/Documents/ITU/Semester3/RP_Greenland/RP_Greenland/Scripts/functions_testing.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mdel\u001b[39;00m df_list\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/linas/OneDrive/Documents/ITU/Semester3/RP_Greenland/RP_Greenland/Scripts/functions_testing.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m/mnt/c/Users/linas/OneDrive/Documents/ITU/Semester3/RP_Greenland/RP_Greenland/.venv/lib/python3.9/site-packages/pandas/util/_decorators.py:317\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    312\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    313\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    314\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    315\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(inspect\u001b[39m.\u001b[39mcurrentframe()),\n\u001b[1;32m    316\u001b[0m     )\n\u001b[0;32m--> 317\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/mnt/c/Users/linas/OneDrive/Documents/ITU/Semester3/RP_Greenland/RP_Greenland/.venv/lib/python3.9/site-packages/pandas/core/reshape/concat.py:369\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[39m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, allowed_args\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mobjs\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    148\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconcat\u001b[39m(\n\u001b[1;32m    149\u001b[0m     objs: Iterable[NDFrame] \u001b[39m|\u001b[39m Mapping[HashableT, NDFrame],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    158\u001b[0m     copy: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    159\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m    160\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[39m    Concatenate pandas objects along a particular axis.\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[39m    1   3   4\u001b[39;00m\n\u001b[1;32m    368\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 369\u001b[0m     op \u001b[39m=\u001b[39m _Concatenator(\n\u001b[1;32m    370\u001b[0m         objs,\n\u001b[1;32m    371\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m    372\u001b[0m         ignore_index\u001b[39m=\u001b[39;49mignore_index,\n\u001b[1;32m    373\u001b[0m         join\u001b[39m=\u001b[39;49mjoin,\n\u001b[1;32m    374\u001b[0m         keys\u001b[39m=\u001b[39;49mkeys,\n\u001b[1;32m    375\u001b[0m         levels\u001b[39m=\u001b[39;49mlevels,\n\u001b[1;32m    376\u001b[0m         names\u001b[39m=\u001b[39;49mnames,\n\u001b[1;32m    377\u001b[0m         verify_integrity\u001b[39m=\u001b[39;49mverify_integrity,\n\u001b[1;32m    378\u001b[0m         copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m    379\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m    380\u001b[0m     )\n\u001b[1;32m    382\u001b[0m     \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39mget_result()\n",
      "File \u001b[0;32m/mnt/c/Users/linas/OneDrive/Documents/ITU/Semester3/RP_Greenland/RP_Greenland/.venv/lib/python3.9/site-packages/pandas/core/reshape/concat.py:426\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    423\u001b[0m     objs \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(objs)\n\u001b[1;32m    425\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(objs) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 426\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo objects to concatenate\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    428\u001b[0m \u001b[39mif\u001b[39;00m keys \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    429\u001b[0m     objs \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(com\u001b[39m.\u001b[39mnot_none(\u001b[39m*\u001b[39mobjs))\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "df = import_data(date_from, date_to, df_path)\n",
    "df=df[['mw_value', 'opt_value', 'date', 'mean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_data(df, removeMaskedClouds = True, removeNoMelt = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'import_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/Users/linas/OneDrive/Documents/ITU/Semester3/RP_Greenland/RP_Greenland/Scripts/functions_testing.ipynb Cell 23\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/linas/OneDrive/Documents/ITU/Semester3/RP_Greenland/RP_Greenland/Scripts/functions_testing.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m df \u001b[39m=\u001b[39m import_data(date_from, date_to, df_path)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/linas/OneDrive/Documents/ITU/Semester3/RP_Greenland/RP_Greenland/Scripts/functions_testing.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m df\u001b[39m=\u001b[39mdf[[\u001b[39m'\u001b[39m\u001b[39mmw_value\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mopt_value\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/linas/OneDrive/Documents/ITU/Semester3/RP_Greenland/RP_Greenland/Scripts/functions_testing.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m a, b \u001b[39m=\u001b[39m cross_validation(df, [\u001b[39m'\u001b[39m\u001b[39mmw_value\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m'\u001b[39m], model_decisionTree, n_splits \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m, hyperparameters \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'import_data' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "a, b = cross_validation(df, ['mw_value', 'mean'], model_decisionTree, n_splits = 5, hyperparameters = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.74it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "x                     0\n",
       "y                     0\n",
       "mw_value              0\n",
       "opt_value             0\n",
       "col                   0\n",
       "row                   0\n",
       "v1                14044\n",
       "v2                 6648\n",
       "v3                14036\n",
       "v4                 7576\n",
       "v5                    0\n",
       "v6                 7576\n",
       "v7                14036\n",
       "v8                 6648\n",
       "v9                14044\n",
       "date                  0\n",
       "mean                  0\n",
       "elevation_data        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = import_data(date_from, date_to, df_path)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x                    0\n",
       "y                    0\n",
       "mw_value             0\n",
       "opt_value            0\n",
       "col                  0\n",
       "row                  0\n",
       "v1                1112\n",
       "v2                 453\n",
       "v3                1829\n",
       "v4                 710\n",
       "v5                   0\n",
       "v6                1378\n",
       "v7                2135\n",
       "v8                1419\n",
       "v9                2738\n",
       "date                 0\n",
       "mean                 0\n",
       "elevation_data       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['mw_value'] != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_tif(data, path_file_metadata, path_out):\n",
    "    \"\"\"\n",
    "    Function to convert data to tif file.\n",
    "    Arguments:\n",
    "        data: new file\n",
    "        path_file_metadata: tif file with metadata matching expected output tif file\n",
    "        path_out: output tif file destination and name path\n",
    "    Returns:\n",
    "        .tif file\n",
    "    \"\"\"\n",
    "    with rasterio.open(path_file_metadata) as src:\n",
    "        kwargs1 = src.meta.copy()\n",
    "\n",
    "    with rasterio.open(path_out, \"w\", **kwargs1) as dst:\n",
    "        dst.write_band(1, data)  # numpy array or xarray\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_prediction_tif(X_pred, y_predicted, path_out):\n",
    "    \"\"\"\n",
    "    Function to write predictions to .tif.\n",
    "    Arguments:\n",
    "        X_pred: data to be predicted on.\n",
    "        y_predicted: predicted labels in array, or pandas series.\n",
    "        path_out: path to save .tif file with file name.\n",
    "    Returns: No return, writes data to path.\n",
    "    \"\"\"\n",
    "    # join prediction and coordinates (row, col)\n",
    "    X_pred[\"prediction\"] = y_predicted\n",
    "\n",
    "    # original matrix shape:\n",
    "    nan_matrix = np.full((2663, 1462), np.nan)\n",
    "\n",
    "    for row in tqdm(X_pred.iterrows()):  # fix progress bar?\n",
    "        row_index = int(row[1][\"row\"])\n",
    "        col_index = int(row[1][\"col\"])\n",
    "        pred_val = row[1][\"prediction\"]\n",
    "        nan_matrix[row_index][col_index] = pred_val\n",
    "\n",
    "    # file to take reference metadata from is interpolated transformed file\n",
    "    path_metadata_reference = r\"../Data/microwave-rs/mw_interpolated/2019-07-01_mw.tif\"\n",
    "\n",
    "    convert_to_tif(nan_matrix, path_metadata_reference, path_out)\n",
    "\n",
    "    return\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.14 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c1c6eaedbd5b3fcd114378d998a879d4f50715202363f6507059361ed549ecef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
