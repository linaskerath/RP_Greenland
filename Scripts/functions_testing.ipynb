{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions testing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_meanBenchmark(y_train, y_test):\n",
    "    \"\"\"\n",
    "    Creates predictions for mean benchmark.\n",
    "\n",
    "    Args:\n",
    "        y_train (pandas.DataFrame): Dataframe with train labels, one column.\n",
    "\n",
    "        y_test (pandas.DataFrame): Dataframe with test labels, one column.\n",
    "\n",
    "    Returns:\n",
    "        list: Lists with predicted values for test set.\n",
    "    \"\"\"\n",
    "\n",
    "    y_predicted = np.full((1, len(y_test)), y_train.mean())[0]\n",
    "\n",
    "    return y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_mwBenchmark(X_test):\n",
    "    \"\"\"\n",
    "    Creates predictions for microwave benchmark by comparing the mw and opt datasets directly.\n",
    "\n",
    "    Args:\n",
    "        X_test (pandas.DataFrame): Dataframe with test data.\n",
    "\n",
    "    Returns:\n",
    "        list: Lists with predicted values for test set.\n",
    "    \"\"\"\n",
    "\n",
    "    y_predicted = X_test['mw_value']\n",
    "\n",
    "    return y_predicted"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### saving functions, to be updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_prediction_tif(X_pred, y_predicted, path_out):\n",
    "    \"\"\"\n",
    "    Function to write predictions to .tif.\n",
    "    Arguments:\n",
    "        X_pred: data to be predicted on.\n",
    "        y_predicted: predicted labels in array, or pandas series.\n",
    "        path_out: path to save .tif file with file name.\n",
    "    Returns: No return, writes data to path.\n",
    "    \"\"\"\n",
    "    # join prediction and coordinates (row, col)\n",
    "    X_pred[\"prediction\"] = y_predicted\n",
    "\n",
    "    # original matrix shape:\n",
    "    nan_matrix = np.full((2663, 1462), np.nan)\n",
    "\n",
    "    for row in tqdm(X_pred.iterrows()):  # fix progress bar?\n",
    "        row_index = int(row[1][\"row\"])\n",
    "        col_index = int(row[1][\"col\"])\n",
    "        pred_val = row[1][\"prediction\"]\n",
    "        nan_matrix[row_index][col_index] = pred_val\n",
    "\n",
    "    # file to take reference metadata from is interpolated transformed file\n",
    "    path_metadata_reference = r\"../Data/microwave-rs/mw_interpolated/2019-07-01_mw.tif\"\n",
    "\n",
    "    convert_to_tif(nan_matrix, path_metadata_reference, path_out)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def convert_to_tif(data, path_file_metadata, path_out):\n",
    "    \"\"\"\n",
    "    Function to convert data to tif file.\n",
    "    Arguments:\n",
    "        data: new file\n",
    "        path_file_metadata: tif file with metadata matching expected output tif file\n",
    "        path_out: output tif file destination and name path\n",
    "    Returns:\n",
    "        .tif file\n",
    "    \"\"\"\n",
    "    with rasterio.open(path_file_metadata) as src:\n",
    "        kwargs1 = src.meta.copy()\n",
    "\n",
    "    with rasterio.open(path_out, \"w\", **kwargs1) as dst:\n",
    "        dst.write_band(1, data)  # numpy array or xarray\n",
    "    return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thesis 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt # to plot kmeans splits\n",
    "import itertools"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script contains all necessary functions for the training pipeline.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "#from sklearn.model_selection import TimeSeriesSplit\n",
    "#from sklearn.tree import DecisionTreeRegressor\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt # to plot kmeans splits\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "#############################################\n",
    "# Data preparation functions\n",
    "#############################################\n",
    "\n",
    "def import_data(date_from: str, date_to: str, df_path: str):\n",
    "    \"\"\"\n",
    "    Imports data and merges into one dataframe.\n",
    "\n",
    "    Args:\n",
    "        date_from (format: 'yyyy-mm-dd'): Period starting date (included).\n",
    "\n",
    "        date_to (format: 'yyyy-mm-dd'): Period end date (included).\n",
    "\n",
    "        df_path: Path to folder with daily data files.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: Dataframe with all merged data.\n",
    "    \"\"\"\n",
    "\n",
    "    date_range = pd.date_range(date_from, date_to)  # both ends included\n",
    "    date_range = [str(day.date()) for day in date_range]\n",
    "    df_list = []\n",
    "\n",
    "    for melt_date in tqdm(date_range):\n",
    "        try:  # bc some days are empty\n",
    "            file = pd.read_parquet(\n",
    "                df_path + \"melt_\" + melt_date + \"_extended.parquet.gzip\", index=False\n",
    "            )\n",
    "            df_list.append(file)  # list of df\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    df = pd.concat(df_list, axis=0)  # concat af df to one\n",
    "    del df_list\n",
    "    return df\n",
    "\n",
    "\n",
    "def remove_data(df, removeMaskedClouds = True, removeNoMelt = True):\n",
    "    \"\"\"\n",
    "    Removes missing/masked mw and opt data from dataframe.\n",
    "    Used for training and testing, not predicting.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): Full train/ test dataframe.\n",
    "\n",
    "        removeMaskedClouds (bool): True for train and test data, removes masked data from opt data.\n",
    "                                   False for predicting data, keeps masked opt data.\n",
    "\n",
    "        removeNoMelt (bool): True for train and test data, removes non-melt areas from mw data.\n",
    "                             False for predicting data, keeps non-melt areas. \n",
    "    Returns:\n",
    "        pandas.DataFrame: The same dataframe with removed water (and masked data).\n",
    "    \"\"\"\n",
    "    # df = df[df['mw_value'] != -1] \n",
    "    \n",
    "    if removeMaskedClouds == True:\n",
    "        df = df[df[\"opt_value\"] != -1]\n",
    "\n",
    "    if removeNoMelt == True:\n",
    "        melt = pd.read_parquet(r\"../Data/split_indexes/noMelt_indexes.parquet\", index= False)\n",
    "        df = df.merge(melt, how = 'left', on = [\"y\",'x'])\n",
    "        df = df[df['melt'] == 1]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def data_normalization(df, feature):\n",
    "    \"\"\"\n",
    "    Normalizes data with min-max (linear) or Z-score normalization depending on feature.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): Full train/ test dataframe.\n",
    "\n",
    "        feature (string): Name of feature to be normalized.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The same dataframe with normalized feature.\n",
    "    \"\"\"\n",
    "    # TODO add / correct opt_value and elevation_data\n",
    "\n",
    "    minmax_features = [\n",
    "        \"col\",\n",
    "        \"row\",\n",
    "        \"mean_3\",\n",
    "        \"mean_9\",\n",
    "        \"sum_5\",\n",
    "        \"mw_value_yesterday\",\n",
    "        \"mw_value_7_day_average\",\n",
    "        \"hours_of_daylight\",\n",
    "        \"slope_data\",\n",
    "        \"aspect_data\",\n",
    "        \"distance_to_margin\",\n",
    "    ]\n",
    "    zscore_features = [\"opt_value\", \"elevation_data\"]\n",
    "\n",
    "    if feature in minmax_features:\n",
    "        if feature == \"col\":\n",
    "            min, max = 0, 1461\n",
    "        elif feature == \"row\":\n",
    "            min, max = 0, 2662\n",
    "        elif feature == \"mean_3\":\n",
    "            min, max = 0, 1\n",
    "        elif feature == \"mean_9\":\n",
    "            min, max = 0, 1\n",
    "        elif feature == \"sum_5\":\n",
    "            min, max = 0, 25\n",
    "        elif feature == \"mw_value_yesterday\":\n",
    "            min, max = 0, 1\n",
    "        elif feature == \"mw_value_7_day_average\":\n",
    "            min, max = 0, 1\n",
    "        elif feature == \"hours_of_daylight\":\n",
    "            min, max = 0, 24\n",
    "        elif feature == \"slope_data\":\n",
    "            min, max = 0, 90\n",
    "        elif feature == \"aspect_data\":\n",
    "            min, max = -1, 1\n",
    "        else:\n",
    "            min, max = 1, 500\n",
    "\n",
    "        df[feature] = (df[feature] - min) / (max - min)\n",
    "\n",
    "    elif feature in zscore_features:\n",
    "        scaler = StandardScaler()\n",
    "        df[feature] = scaler.fit_transform(df[[feature]])\n",
    "    else:\n",
    "        print(\"Feature not found.\")\n",
    "\n",
    "    return df\n",
    "\n",
    "#############################################\n",
    "# Benchmark functions\n",
    "#############################################\n",
    "\n",
    "\n",
    "def model_meanBenchmark(y_train, y_test):\n",
    "    \"\"\"\n",
    "    Creates predictions for mean benchmark.\n",
    "\n",
    "    Args:\n",
    "        y_train (pandas.DataFrame): Dataframe with train labels, one column.\n",
    "\n",
    "        y_test (pandas.DataFrame): Dataframe with test labels, one column.\n",
    "\n",
    "    Returns:\n",
    "        list: Lists with predicted values for test set.\n",
    "    \"\"\"\n",
    "\n",
    "    y_predicted = np.full((1, len(y_test)), y_train.mean())[0]\n",
    "\n",
    "    return y_predicted\n",
    "\n",
    "\n",
    "def model_mwBenchmark(X_test):\n",
    "    \"\"\"\n",
    "    Creates predictions for microwave benchmark by comparing the mw and opt datasets directly.\n",
    "\n",
    "    Args:\n",
    "        X_test (pandas.DataFrame): Dataframe with test data.\n",
    "\n",
    "    Returns:\n",
    "        list: Lists with predicted values for test set.\n",
    "    \"\"\"\n",
    "\n",
    "    y_predicted = X_test[\"mw_value\"]\n",
    "\n",
    "    return y_predicted\n",
    "\n",
    "\n",
    "#############################################\n",
    "# Model training CV\n",
    "#############################################\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "# class Model:\n",
    "#     \"\"\" \n",
    "#     This class contains models. \n",
    "#     After training it also contains performance scores and the hyperparameters used to train it.\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self, model):  \n",
    "#         self.model = model\n",
    "#         self.hyperparameters = [] # list of dictionaries with hyperparameters\n",
    "    \n",
    "#     # def create_hyperparameter_grid(self, hyperparameters):\n",
    "#     #     \"\"\"\n",
    "#     #     Creates a grid with all possible combinations of hyperparameters.\n",
    "\n",
    "#     #     Args:\n",
    "#     #         hyperparameters (dict): Dictionary with hyperparameters.\n",
    "\n",
    "#     #     Returns:\n",
    "#     #         list: List with dictionaries with all possible combinations of hyperparameters.\n",
    "#     #     \"\"\"\n",
    "#     #     hyperparameter_grid = []\n",
    "#     #     for i in range(len(hyperparameters)):\n",
    "#     #         hyperparameter_grid.append(list(hyperparameters.values())[i])\n",
    "#     #     hyperparameter_grid = list(itertools.product(*hyperparameter_grid))\n",
    "#     #     hyperparameter_grid = [dict(zip(hyperparameters.keys(), values)) for values in hyperparameter_grid]\n",
    "#     #     return hyperparameter_grid\n",
    "\n",
    "#     def create_hyperparameter_grid(self, hyperparameters):    \n",
    "#         return ParameterGrid(hyperparameters)\n",
    "\n",
    "\n",
    "#     def __kmeans_split(self, df, loop, plot = False):\n",
    "#         \"\"\" \n",
    "#         This function splits the data into 5 areas based on the kmeans algorithm.\n",
    "\n",
    "#         Args:\n",
    "#             df (pandas.DataFrame): Dataframe with data.\n",
    "\n",
    "#             loop (str): 'inner' or 'outer' loop.\n",
    "\n",
    "#             plot (bool): If True, plots the kmeans split.\n",
    "\n",
    "#         Returns:\n",
    "#             pandas.DataFrame: Dataframe with added column with kmeans split.\n",
    "        \n",
    "#         \"\"\"\n",
    "#         kmeans = KMeans(n_clusters=5, random_state=0, n_init=\"auto\").fit(df[['x','y']])\n",
    "#         if loop == 'inner':\n",
    "#             df['inner_area'] = kmeans.labels_\n",
    "#         elif loop == 'outer':\n",
    "#             df['outer_area'] = kmeans.labels_\n",
    "\n",
    "#         if plot == True:\n",
    "#             print(df[loop+'_area'].value_counts())\n",
    "#             plt.scatter(df['x'], df['y'], c=df[loop+'_area'], edgecolor='none', s = 0.05)\n",
    "#             plt.show()\n",
    "#         return df\n",
    "    \n",
    "#     def __train_test_split(self, df, columns, split_index):\n",
    "#         \"\"\" \n",
    "#         This function splits the data into train and test set.\n",
    "\n",
    "#         Args:\n",
    "#             df (pandas.DataFrame): Dataframe with data.\n",
    "\n",
    "#             columns (list): List with column names to be used in the model.\n",
    "\n",
    "#             split_index (int): Index of the split (loop).\n",
    "\n",
    "#         Returns:\n",
    "#             pandas.DataFrame: Dataframe with added column with kmeans split.\n",
    "#         \"\"\"\n",
    "#         inner_train = df[df['inner_area'] != split_index]\n",
    "#         inner_test  = df[df['inner_area'] == split_index]\n",
    "#         train_X = inner_train[columns]\n",
    "#         train_y = inner_train[[\"opt_value\"]]\n",
    "#         test_X = inner_test[columns]\n",
    "#         test_y = inner_test[[\"opt_value\"]] \n",
    "#         return train_X, train_y, test_X, test_y\n",
    "\n",
    "#     def __inner_loop_tune_hyperparameters(self, df, columns):\n",
    "#         \"\"\" \n",
    "#         This function performs hyperparameter tuning in (inner loop of nested cross-validation).\n",
    "        \n",
    "#         Args:\n",
    "#             df (pandas.DataFrame): Dataframe with data.\n",
    "\n",
    "#             columns (list): List with column names to be used in the model.\n",
    "\n",
    "#         Returns:\n",
    "#             dict: Dictionary with best hyperparameters.\n",
    "#         \"\"\"\n",
    "#         all_inner_loops_hyperparameter_scores= []\n",
    "#         for inner_split in df['inner_area'].unique():\n",
    "#             inner_train_X, inner_train_y, inner_test_X, inner_test_y = self.__train_test_split(df, columns, inner_split)                \n",
    "#             hyperparameter_scores = []\n",
    "#             if isinstance(self.hyperparameters, list):\n",
    "#                 for hyperparams in self.hyperparameters:\n",
    "#                     regressor = self.model(random_state=0, **hyperparams).fit(inner_train_X, inner_train_y)\n",
    "#                     y_predicted_test = regressor.predict(inner_test_X)\n",
    "#                     hyperparameter_scores.append(mean_squared_error(inner_test_y, y_predicted_test, squared=False))\n",
    "#             else:\n",
    "#                 print('hyperparameters must be a list')\n",
    "#             all_inner_loops_hyperparameter_scores.append(hyperparameter_scores)\n",
    "#         mean_hyperparameters = np.mean(all_inner_loops_hyperparameter_scores, axis=0)\n",
    "#         best_inner_hyperparameters = self.hyperparameters[np.argmin(mean_hyperparameters)] # not argmax because we want to minimize the error\n",
    "#         return best_inner_hyperparameters\n",
    "    \n",
    "#     def spatial_cv(self, df, columns):\n",
    "#         \"\"\" \n",
    "#         This function performs spatial cross-validation.\n",
    "        \n",
    "#         Args:\n",
    "#             df (pandas.DataFrame): Dataframe with data.\n",
    "            \n",
    "#             columns (list): List with column names to be used in the model.\n",
    "\n",
    "#         Returns:\n",
    "#             Nothing. But it assigns the RMSE and R2 scores for the train and test set to the model object.\n",
    "#                      It also assigns the best hyperparameters, predicted and real values of each outer split to the model object.\n",
    "#         \"\"\"\n",
    "#         rmse_list_train = []\n",
    "#         rmse_list_test = []\n",
    "#         r2_list_train = []\n",
    "#         r2_list_test = []\n",
    "#         self.best_hyperparameters = []\n",
    "#         predictions_train = []\n",
    "#         predictions_test = []\n",
    "#         real_values_train = []\n",
    "#         real_values_test = []\n",
    "        \n",
    "#         df = self.__kmeans_split(df, 'outer') #, plot = True #df = self.__cv_split_outer_loop(df)\n",
    "#         for outer_split in df['outer_area'].unique():\n",
    "#             #if outer_split == 1: # remove\n",
    "#             train = df[df['outer_area'] != outer_split]\n",
    "#             train = self.__kmeans_split(train, 'inner') #train = self.__cv_split_inner_loop(train)\n",
    "#             best_hyperparam= self.__inner_loop_tune_hyperparameters(train, columns)\n",
    "#             self.best_hyperparameters.append(best_hyperparam)\n",
    "            \n",
    "#             train_X, train_y, test_X, test_y = self.__train_test_split(train, columns, outer_split)\n",
    "#             print(f'length train_X: {len(train_X)}, length train_y: {len(train_y)}, length test_X: {len(test_X)}, length test_y: {len(test_y)}')\n",
    "#             regressor = self.model(random_state=0, **best_hyperparam).fit(train_X, train_y)\n",
    "#             train_y_predicted = regressor.predict(train_X)\n",
    "#             test_y_predicted  = regressor.predict(test_X )\n",
    "#             predictions_train.append(train_y_predicted)\n",
    "#             predictions_test.append(test_y_predicted)\n",
    "#             real_values_train.append(train_y)\n",
    "#             real_values_test.append(test_y)\n",
    "\n",
    "#             rmse_list_train.append(mean_squared_error(train_y, train_y_predicted))\n",
    "#             rmse_list_test.append(mean_squared_error(test_y, test_y_predicted))\n",
    "#             r2_list_train.append(r2_score(train_y, train_y_predicted))\n",
    "#             r2_list_test.append(r2_score(test_y, test_y_predicted))\n",
    "\n",
    "#             # else: # tb removed\n",
    "#             #     continue\n",
    "#         # results:\n",
    "#         self.rmse_train = np.mean(rmse_list_train)\n",
    "#         self.rmse_std_train = np.std(rmse_list_train)\n",
    "#         self.rmse_test = np.mean(rmse_list_test)\n",
    "#         self.rmse_std_test = np.std(rmse_list_test)\n",
    "#         self.r2_train = np.mean(r2_list_train)\n",
    "#         self.r2_std_train = np.std(r2_list_train)\n",
    "#         self.r2_test = np.mean(r2_list_test)\n",
    "#         self.r2_std_test = np.std(r2_list_test)\n",
    "        \n",
    "#         self.outer_loop_results = {'rmse_list_train': rmse_list_train,\n",
    "#                                    'rmse_list_test' : rmse_list_test,\n",
    "#                                    'r2_list_train'  : r2_list_train,\n",
    "#                                    'r2_list_test'   : r2_list_test}\n",
    "        \n",
    "#         self.outer_loop_predictions = {'train_y_predicted': predictions_train,\n",
    "#                                        'test_y_predicted' : predictions_test}\n",
    "#         self.outer_loop_real_values = {'train_y': real_values_train,\n",
    "#                                         'test_y' : real_values_test}\n",
    "#         return\n",
    "\n",
    "#     def get_results(self):\n",
    "#         \"\"\" \n",
    "#         This function prints the results of the model in a table.\n",
    "#         \"\"\"\n",
    "#         results = pd.DataFrame({'Metric': ['RMSE', 'RMSE_std', 'R2', 'R2_std'],\n",
    "#                                 'Train': [self.rmse_train, self.rmse_std_train ,self.r2_train, self.r2_std_train],\n",
    "#                                 'Test': [self.rmse_test, self.rmse_std_test, self.r2_test, self.r2_std_test]})\n",
    "#         print(results)\n",
    "#         return \n",
    "    \n",
    "#     def get_attributes(self):\n",
    "#         \"\"\" \n",
    "#         This function prints the attributes of the model.\n",
    "#         \"\"\"\n",
    "#         for attribute, value in self.__dict__.items():\n",
    "#             print(attribute, '=', value)\n",
    "#         return\n",
    "    \n",
    "\n",
    "#############################################\n",
    "\n",
    "def save_object(obj):\n",
    "    \"\"\" \n",
    "    This function saves an object to a pickle file.\n",
    "\n",
    "    Args:\n",
    "        obj (object): Object to be saved.\n",
    "\n",
    "        filename (str): Name of the file to be saved, with extension, without path unless a subfolder is desired.\n",
    "    \"\"\"\n",
    "    filename = r'../Models/' + obj.name + '.pkl'\n",
    "    with open(filename, 'wb') as outp:  # Overwrites any existing file.\n",
    "        pickle.dump(obj, outp, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "def load_object(filename):\n",
    "    \"\"\" \n",
    "    This function loads an object from a pickle file.\n",
    "    \n",
    "    Args:\n",
    "        filename (str): Name of the file to be loaded, with extension, without path unless a subfolder is desired.\n",
    "        \n",
    "    Returns:\n",
    "            obj (object): Loaded object.\n",
    "    \"\"\"\n",
    "    filename = r'../Models/' + filename + '.pkl'\n",
    "    with open(filename, 'rb') as inp:\n",
    "        obj = pickle.load(inp)\n",
    "    return obj\n",
    "\n",
    "#############################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# Model training CV\n",
    "#############################################\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "class Model:\n",
    "    \"\"\" \n",
    "    This class contains models. \n",
    "    After training it also contains performance scores and the hyperparameters used to train it.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, name):  \n",
    "        self.model = model\n",
    "        self.hyperparameters = [] # list of dictionaries with hyperparameters\n",
    "        self.name = name\n",
    "\n",
    "    def create_hyperparameter_grid(self, hyperparameters):\n",
    "        \"\"\"\n",
    "        This function creates a grid of hyperparameters.\n",
    "        \n",
    "        Args:\n",
    "            hyperparameters (dict): Dictionary with hyperparameters.\n",
    "            \n",
    "        Returns:\n",
    "            list: List of dictionaries with hyperparameters.\n",
    "        \"\"\"\n",
    "        return ParameterGrid(hyperparameters)\n",
    "\n",
    "\n",
    "    def __kmeans_split(self, df, split_variable_name, plot = False):\n",
    "        \"\"\" \n",
    "        This function splits the data into 5 areas based on the kmeans algorithm.\n",
    "\n",
    "        Args:\n",
    "            df (pandas.DataFrame): Dataframe with data.\n",
    "\n",
    "            split_variable_name (str): name for the column with the kmeans split. Eg. 'inner_area' or 'outer_area' loop.\n",
    "\n",
    "            plot (bool): If True, plots the kmeans split.\n",
    "\n",
    "        Returns:\n",
    "            pandas.DataFrame: Dataframe with added column with kmeans split.\n",
    "        \"\"\"\n",
    "        kmeans = KMeans(n_clusters=5, n_init=\"auto\").fit(df[['x','y']]) #  random_state=0,\n",
    "        df[split_variable_name] = kmeans.labels_\n",
    "\n",
    "        if plot == True:\n",
    "            print(df[split_variable_name].value_counts())\n",
    "            plt.scatter(df['x'], df['y'], c=df[split_variable_name], edgecolor='none', s = 0.05)\n",
    "            plt.show()\n",
    "        return df\n",
    "    \n",
    "    def __train_test_split(self, df, columns, split_variable_name, split_index):\n",
    "        \"\"\" \n",
    "        This function splits the data into train and test set.\n",
    "\n",
    "        Args:\n",
    "            df (pandas.DataFrame): Dataframe with data.\n",
    "\n",
    "            columns (list): List with column names to be used in the model.\n",
    "\n",
    "            split_variable_name (str): name of column with kmeans split.\n",
    "\n",
    "            split_index (int): Index of the split (loop).\n",
    "\n",
    "        Returns:\n",
    "            pandas.DataFrame: Dataframe with added column with kmeans split.\n",
    "        \"\"\"\n",
    "        inner_train = df[df[split_variable_name] != split_index]\n",
    "        inner_test  = df[df[split_variable_name] == split_index]\n",
    "        train_X = inner_train[columns]\n",
    "        train_y = inner_train[[\"opt_value\"]]\n",
    "        test_X = inner_test[columns]\n",
    "        test_y = inner_test[[\"opt_value\"]] \n",
    "        return train_X, train_y, test_X, test_y\n",
    "\n",
    "    def __tune_hyperparameters(self, df, columns, split_variable_name):\n",
    "        \"\"\" \n",
    "        This function performs hyperparameter tuning in (inner loop of nested cross-validation).\n",
    "        \n",
    "        Args:\n",
    "            df (pandas.DataFrame): Dataframe with data.\n",
    "\n",
    "            columns (list): List with column names to be used in the model.\n",
    "\n",
    "            split_variable_name (str): name of column with kmeans split.\n",
    "\n",
    "        Returns:\n",
    "            dict: Dictionary with best hyperparameters.\n",
    "        \"\"\"\n",
    "        all_hyperparameter_scores= []\n",
    "        for split in df[split_variable_name].unique():\n",
    "            train_X, train_y, test_X, test_y = self.__train_test_split(df, columns, split_variable_name, split)                \n",
    "            one_loop_hyperparameter_scores = []\n",
    "            if isinstance(self.hyperparameters, list):\n",
    "                for hyperparams in self.hyperparameters:\n",
    "                    regressor = self.model(random_state=0, **hyperparams).fit(itrain_X, train_y)\n",
    "                    y_predicted_test = regressor.predict(test_X)\n",
    "                    one_loop_hyperparameter_scores.append(mean_squared_error(test_y, y_predicted_test, squared=False))\n",
    "            else:\n",
    "                print('hyperparameters must be a list')\n",
    "            all_hyperparameter_scores.append(one_loop_hyperparameter_scores)\n",
    "        mean_hyperparameters = np.mean(all_hyperparameter_scores, axis=0)\n",
    "        best_hyperparameters = self.hyperparameters[np.argmin(mean_hyperparameters)] # not argmax because we want to minimize the error\n",
    "        return best_hyperparameters\n",
    "\n",
    "\n",
    "    def __save_dates(self, df):\n",
    "        \"\"\" \n",
    "        This function saves the dates of the train and test set.\n",
    "        \n",
    "        Args:\n",
    "            df (pandas.DataFrame): Dataframe with data.\n",
    "\n",
    "        Returns:\n",
    "            list of dates used in training/cv.\n",
    "        \"\"\"\n",
    "        return list(df['date'].unique())\n",
    "    \n",
    "    def get_feature_importance(self, model, columns):\n",
    "        \"\"\"\n",
    "        This function returns the feature importance of a model.\n",
    "\n",
    "        Args:\n",
    "            model (sklearn model): Model to get feature importance from.\n",
    "\n",
    "            columns (list): List with column names used in the model.\n",
    "\n",
    "        Returns:\n",
    "            dict: Dictionary with feature importance.\n",
    "        \"\"\"\n",
    "        if isinstance(model, DecisionTreeRegressor):\n",
    "            feature_importance = model.feature_importances_\n",
    "        elif isinstance(model, RandomForestRegressor):\n",
    "            feature_importance = model.feature_importances_\n",
    "        elif isinstance(model, GradientBoostingRegressor):\n",
    "            feature_importance = model.feature_importances_\n",
    "        elif isinstance(model, LinearRegression):\n",
    "            feature_importance = np.abs(model.coef_[0])\n",
    "        elif isinstance(model, Ridge):\n",
    "            feature_importance = np.abs(model.coef_[0])\n",
    "        elif isinstance(model, Lasso):\n",
    "            feature_importance = np.abs(model.coef_[0])\n",
    "        elif isinstance(model, ElasticNet):\n",
    "            feature_importance = np.abs(model.coef_[0])\n",
    "        else:\n",
    "            print('model not supported')\n",
    "\n",
    "        feature_importance_dict = dict(zip(columns, feature_importance))\n",
    "        return feature_importance_dict\n",
    "\n",
    "\n",
    "    def spatial_cv(self, df, columns):\n",
    "        \"\"\" \n",
    "        This function performs spatial cross-validation.\n",
    "        \n",
    "        Args:\n",
    "            df (pandas.DataFrame): Dataframe with data.\n",
    "            \n",
    "            columns (list): List with column names to be used in the model.\n",
    "\n",
    "        Returns:\n",
    "            Nothing. But it assigns the RMSE and R2 scores for the train and test set to the model object.\n",
    "                     It also assigns the best hyperparameters, predicted and real values of each outer split to the model object.\n",
    "        \"\"\"\n",
    "\n",
    "        self.dates = __save_dates(df)\n",
    "        #columns = list(df.columns[df.columns != 'opt_value']) # and date\n",
    "\n",
    "        rmse_list_train = []\n",
    "        rmse_list_test = []\n",
    "        r2_list_train = []\n",
    "        r2_list_test = []\n",
    "        self.best_hyperparameter_list = []\n",
    "        self.feature_importance_list = []\n",
    "        \n",
    "        df = self.__kmeans_split(df, 'outer_area') #, plot = True \n",
    "        for outer_split in df['outer_area'].unique():\n",
    "            train = df[df['outer_area'] != outer_split]\n",
    "            train = self.__kmeans_split(train, 'inner_area')\n",
    "            best_hyperparam = self.__tune_hyperparameters(train, columns, split_variable_name = 'inner_area')\n",
    "            self.best_hyperparameter_list.append(best_hyperparam)\n",
    "            \n",
    "            train_X, train_y, test_X, test_y = self.__train_test_split(train, columns, split_variable_name = 'outer_area', split = outer_split)\n",
    "            #print(f'length train_X: {len(train_X)}, length train_y: {len(train_y)}, length test_X: {len(test_X)}, length test_y: {len(test_y)}')\n",
    "            regressor = self.model(random_state=0, **best_hyperparam).fit(train_X, train_y)\n",
    "            self.feature_importance_list.append(self.get_feature_importance(regressor, columns))\n",
    "\n",
    "            train_y_predicted = regressor.predict(train_X)\n",
    "            test_y_predicted  = regressor.predict(test_X )\n",
    "\n",
    "            rmse_list_train.append(mean_squared_error(train_y, train_y_predicted))\n",
    "            rmse_list_test.append(mean_squared_error(test_y, test_y_predicted))\n",
    "            r2_list_train.append(r2_score(train_y, train_y_predicted))\n",
    "            r2_list_test.append(r2_score(test_y, test_y_predicted))\n",
    "\n",
    "        # results:\n",
    "        self.rmse_train = np.mean(rmse_list_train)\n",
    "        self.rmse_std_train = np.std(rmse_list_train)\n",
    "        self.rmse_test = np.mean(rmse_list_test)\n",
    "        self.rmse_std_test = np.std(rmse_list_test)\n",
    "        self.r2_train = np.mean(r2_list_train)\n",
    "        self.r2_std_train = np.std(r2_list_train)\n",
    "        self.r2_test = np.mean(r2_list_test)\n",
    "        self.r2_std_test = np.std(r2_list_test)\n",
    "        \n",
    "\n",
    "        df = self.__kmeans_split(df, 'final_split_areas')\n",
    "        for split in df['final_split_areas'].unique():\n",
    "            self.final_hyperparameters = self.__tune_hyperparameters(df, columns, split_variable_name = 'final_split_areas')\n",
    "\n",
    "        self.final_model = self.model(random_state=0, **self.final_hyperparameters).fit(df[columns], df['opt_value']) \n",
    "        self.final_feature_importance = self.get_feature_importance(self.final_model, columns)\n",
    "        \n",
    "        return\n",
    "\n",
    "\n",
    "        \n",
    "    def get_results(self):\n",
    "        \"\"\" \n",
    "        This function prints the results of the model in a table.\n",
    "        \"\"\"\n",
    "        results = pd.DataFrame({'Metric': ['RMSE', 'RMSE_std', 'R2', 'R2_std'],\n",
    "                                'Train': [self.rmse_train, self.rmse_std_train ,self.r2_train, self.r2_std_train],\n",
    "                                'Test': [self.rmse_test, self.rmse_std_test, self.r2_test, self.r2_std_test]})\n",
    "        print(results)\n",
    "        return \n",
    "    \n",
    "    def get_attributes(self):\n",
    "        \"\"\" \n",
    "        This function prints the attributes of the model.\n",
    "        \"\"\"\n",
    "        for attribute, value in self.__dict__.items():\n",
    "            print(attribute, '=', value)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "yeet = Model(GradientBoostingRegressor, 'oof')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model = <class 'sklearn.ensemble._gb.GradientBoostingRegressor'>\n",
      "hyperparameters = []\n",
      "name = oof\n"
     ]
    }
   ],
   "source": [
    "yeet.get_attributes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'oof'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yeet.name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = r\"../Data/combined/dataframe_extended/\"\n",
    "\n",
    "date_from = '2019-07-01'\n",
    "date_to = '2019-07-04'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:05<00:00,  1.43s/it]\n"
     ]
    }
   ],
   "source": [
    "data = import_data(date_from, date_to, df_path)\n",
    "data=data[['x', 'y','mw_value', 'opt_value', 'date', 'mean_3']]\n",
    "data = remove_data(data, removeMaskedClouds = True, removeNoMelt = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = [{'max_depth': 5, 'min_samples_leaf': 5, 'min_samples_split': 5}]\n",
    "dt2 = trainedModel(model = DecisionTreeRegressor, hyperparameters = hyperparameters)\n",
    "\n",
    "# hyp = [{'max_depth':7, 'criterion': 'squared_error'}, {'max_depth':4, 'criterion': 'squared_error'}]\n",
    "# dt = trainedModel(model = DecisionTreeRegressor, hyperparameters = hyp )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dt3= trainedModel(model = DecisionTreeRegressor)#\n",
    "dt3.hyperparameters = [{'max_depth': 5, 'min_samples_leaf': 5, 'min_samples_split': 5}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model = <class 'sklearn.tree._classes.DecisionTreeRegressor'>\n",
      "hyperparameters = [{'max_depth': 4, 'min_samples_leaf': 2}, {'max_depth': 4, 'min_samples_leaf': 5}, {'max_depth': 7, 'min_samples_leaf': 2}, {'max_depth': 7, 'min_samples_leaf': 5}]\n"
     ]
    }
   ],
   "source": [
    "dt3.get_attributes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt3.hyperparameters = dt3.create_hyperparameter_grid({'max_depth':[4, 7], 'min_samples_leaf':[2, 5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length train_X: 2111739, length train_y: 2111739, length test_X: 347960, length test_y: 347960\n",
      "length train_X: 2159733, length train_y: 2159733, length test_X: 403216, length test_y: 403216\n",
      "length train_X: 2514439, length train_y: 2514439, length test_X: 541316, length test_y: 541316\n",
      "length train_X: 2389462, length train_y: 2389462, length test_X: 481919, length test_y: 481919\n",
      "length train_X: 2590000, length train_y: 2590000, length test_X: 321068, length test_y: 321068\n"
     ]
    }
   ],
   "source": [
    "columns = ['x', 'y','mw_value', 'mean_3']\n",
    "dt2.spatial_cv(data, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model = <class 'sklearn.tree._classes.DecisionTreeRegressor'>\n",
      "hyperparameters = [{'max_depth': 5, 'min_samples_leaf': 5, 'min_samples_split': 5}]\n",
      "best_hyperparameters = [{'max_depth': 5, 'min_samples_leaf': 5, 'min_samples_split': 5}, {'max_depth': 5, 'min_samples_leaf': 5, 'min_samples_split': 5}, {'max_depth': 5, 'min_samples_leaf': 5, 'min_samples_split': 5}, {'max_depth': 5, 'min_samples_leaf': 5, 'min_samples_split': 5}, {'max_depth': 5, 'min_samples_leaf': 5, 'min_samples_split': 5}]\n",
      "rmse_train = 0.07946593581442872\n",
      "rmse_std_train = 0.007014737016824507\n",
      "rmse_test = 0.07837360065180628\n",
      "rmse_std_test = 0.010516675275927838\n",
      "r2_train = 0.5319369440969419\n",
      "r2_std_train = 0.035455626742688304\n",
      "r2_test = -0.1907628432111141\n",
      "r2_std_test = 0.7861320413930145\n",
      "outer_loop_results = {'rmse_list_train': [0.07051953227967811, 0.07191474422878381, 0.08839363624136169, 0.08269475423806222, 0.08380701208425778], 'rmse_list_test': [0.06813612194207963, 0.09251454369839324, 0.08577965303519904, 0.08076333909350758, 0.06467434548985188], 'r2_list_train': [0.5975645015666722, 0.504582269245053, 0.5037102785786902, 0.5130746715983466, 0.5407529994959475], 'r2_list_test': [0.16884427979977223, -1.7407770733397108, 0.3780696819350564, 0.2639143603149593, -0.02386546476564777]}\n",
      "outer_loop_predictions = {'train_y_predicted': [array([0.12565089, 0.25670925, 0.25670925, ..., 0.21729266, 0.21729266,\n",
      "       0.21729266]), array([0.34150059, 0.34150059, 0.34150059, ..., 0.21090693, 0.21090693,\n",
      "       0.21090693]), array([0.25910443, 0.25910443, 0.25910443, ..., 0.38638484, 0.38638484,\n",
      "       0.38638484]), array([0.23220022, 0.23220022, 0.23220022, ..., 0.32661467, 0.32661467,\n",
      "       0.32661467]), array([0.377192 , 0.377192 , 0.377192 , ..., 1.5665428, 1.5665428,\n",
      "       1.5665428])], 'test_y_predicted': [array([0.32755834, 0.32755834, 0.32755834, ..., 0.21729266, 0.21729266,\n",
      "       0.21729266]), array([0.38115325, 0.38115325, 0.38115325, ..., 0.3512675 , 0.3512675 ,\n",
      "       0.3512675 ]), array([0.23105573, 0.23105573, 0.23105573, ..., 0.35991964, 0.35991964,\n",
      "       0.35991964]), array([0.89779599, 0.89779599, 0.89779599, ..., 0.20780936, 0.20780936,\n",
      "       0.20780936]), array([0.69741471, 0.69741471, 0.2628513 , ..., 0.19843815, 0.19843815,\n",
      "       0.19843815])]}\n",
      "outer_loop_real_values = {'train_y': [         opt_value\n",
      "20261     0.443058\n",
      "20501     0.586056\n",
      "20502     0.613324\n",
      "20503     0.558280\n",
      "20504     0.557686\n",
      "...            ...\n",
      "4172470   0.004917\n",
      "4172534   0.004048\n",
      "4172535   0.002953\n",
      "4172614   0.000119\n",
      "4172615   0.004234\n",
      "\n",
      "[2111739 rows x 1 columns],          opt_value\n",
      "0         0.016349\n",
      "1         0.000484\n",
      "2         0.000385\n",
      "3         0.188975\n",
      "4         0.236826\n",
      "...            ...\n",
      "4020545   0.939491\n",
      "4020546   0.892015\n",
      "4021059   1.008890\n",
      "4021060   0.994504\n",
      "4021061   0.938852\n",
      "\n",
      "[2159733 rows x 1 columns],          opt_value\n",
      "0         0.016349\n",
      "1         0.000484\n",
      "2         0.000385\n",
      "3         0.188975\n",
      "4         0.236826\n",
      "...            ...\n",
      "4172470   0.004917\n",
      "4172534   0.004048\n",
      "4172535   0.002953\n",
      "4172614   0.000119\n",
      "4172615   0.004234\n",
      "\n",
      "[2514439 rows x 1 columns],          opt_value\n",
      "0         0.016349\n",
      "1         0.000484\n",
      "2         0.000385\n",
      "3         0.188975\n",
      "4         0.236826\n",
      "...            ...\n",
      "4172470   0.004917\n",
      "4172534   0.004048\n",
      "4172535   0.002953\n",
      "4172614   0.000119\n",
      "4172615   0.004234\n",
      "\n",
      "[2389462 rows x 1 columns],          opt_value\n",
      "0         0.016349\n",
      "1         0.000484\n",
      "2         0.000385\n",
      "3         0.188975\n",
      "4         0.236826\n",
      "...            ...\n",
      "3858920   1.526419\n",
      "3858921   1.744906\n",
      "3858922   1.942123\n",
      "3858923   1.685207\n",
      "3859422   1.595677\n",
      "\n",
      "[2590000 rows x 1 columns]], 'test_y': [         opt_value\n",
      "388751    0.002016\n",
      "388752    0.007128\n",
      "388753    0.001408\n",
      "389073    0.001167\n",
      "389074    0.007996\n",
      "...            ...\n",
      "3869070   0.476998\n",
      "3869071   1.730814\n",
      "3869680   0.869880\n",
      "3869681   1.147488\n",
      "3870291   0.870534\n",
      "\n",
      "[347960 rows x 1 columns],          opt_value\n",
      "633143    0.001395\n",
      "633180    0.398256\n",
      "633223    0.000134\n",
      "633224    0.000670\n",
      "633263    0.002456\n",
      "...            ...\n",
      "4172470   0.004917\n",
      "4172534   0.004048\n",
      "4172535   0.002953\n",
      "4172614   0.000119\n",
      "4172615   0.004234\n",
      "\n",
      "[403216 rows x 1 columns],          opt_value\n",
      "435831    0.205974\n",
      "435832    0.193986\n",
      "435833    0.191758\n",
      "436220    0.207379\n",
      "436221    0.216973\n",
      "...            ...\n",
      "3877920   2.000372\n",
      "3877921   2.005731\n",
      "3877922   1.725369\n",
      "3877923   1.791083\n",
      "3877924   1.967093\n",
      "\n",
      "[541316 rows x 1 columns],          opt_value\n",
      "210148    1.540581\n",
      "210941    0.838657\n",
      "210942    1.444272\n",
      "211730    1.371930\n",
      "211731    1.048772\n",
      "...            ...\n",
      "3537876   0.206704\n",
      "3537877   0.169385\n",
      "3538397   0.197490\n",
      "3538398   0.196876\n",
      "3538901   0.198833\n",
      "\n",
      "[481919 rows x 1 columns],          opt_value\n",
      "465098    0.063057\n",
      "465305    0.043774\n",
      "467575    0.000118\n",
      "467754    0.000383\n",
      "467755    0.000193\n",
      "...            ...\n",
      "3906132   0.167935\n",
      "3906133   0.157149\n",
      "3906134   0.166649\n",
      "3906653   0.162955\n",
      "3906654   0.163337\n",
      "\n",
      "[321068 rows x 1 columns]]}\n"
     ]
    }
   ],
   "source": [
    "dt2.get_attributes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_object(dt2, 'test_decision_tree_v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.14 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c1c6eaedbd5b3fcd114378d998a879d4f50715202363f6507059361ed549ecef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
